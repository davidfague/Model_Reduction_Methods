{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Model-Reduction-Methods/blob/main/NR_expand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDTyDy5FaQTn"
      },
      "source": [
        "# Quick Start\n",
        "## The following code shows the main function that is used to reduce a complex cell.\n",
        "\n",
        "complex_cell  # The model cell\n",
        "\n",
        "synapses_list # A list of all synapse on this cell\n",
        "\n",
        "netcon_list   # A list of all netcons for the synapses on the cell\n",
        "\n",
        "import neuron_reduce\n",
        "\n",
        "reduced_cell, synapses_list, netcons_list =  neuron_reduce.subtree_reductor(complex_cell, synapses_list, netcons_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ82bG9gayLw"
      },
      "source": [
        "# Detailed Example\n",
        "## Example copied from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8QAPXTrcKUO",
        "outputId": "5ae06394-f61c-4948-d19b-48871b23737a"
      },
      "outputs": [],
      "source": [
        "%pip install neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37g4VleafuDM"
      },
      "outputs": [],
      "source": [
        "# !pip install neuron_reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9fdloqtbKqg",
        "outputId": "e4cbcd12-315f-4929-fc07-a4c909429c49"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/orena1/neuron_reduce.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_cpnQEPbRRu",
        "outputId": "a3aa47f3-fdde-45f2-d989-a3e92c41481b"
      },
      "outputs": [],
      "source": [
        "# Go to example folder\n",
        "%cd neuron_reduce \n",
        "%cd example\n",
        "# compile the mod files\n",
        "!nrnivmodl mod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD6WbeClr6s2"
      },
      "source": [
        "### Neuron Reduce Functions for experimenting in notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhplZHXugW0_"
      },
      "source": [
        "reducing_methods.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsvUvUHigWhP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This file contains the reduction algorithm itself\n",
        "added the method by Guy to find L and X\n",
        "'''\n",
        "import collections\n",
        "import contextlib\n",
        "import logging\n",
        "import math\n",
        "import cmath\n",
        "\n",
        "from neuron import h\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "CableParams = collections.namedtuple('CableParams',\n",
        "                                     'length, diam, space_const,'\n",
        "                                     'cm, rm, ra, e_pas, electrotonic_length')\n",
        "SynapseLocation = collections.namedtuple('SynapseLocation', 'subtree_index, section_num, x')\n",
        "\n",
        "h('''obfunc lowest_impedance_recursive() { local lowest_impedance, lowest_phase, i   localobj curr_subtree_root, sref1, lowest_imp_vec, lowest_child_subtree_impedance, imp_obj\n",
        "    curr_subtree_root = $o1  // in the first call to the function, this is a root section of a dendritic trunk\n",
        "    imp_obj = $o2\n",
        "    curr_subtree_root.sec {\n",
        "        lowest_impedance = imp_obj.transfer(1) // farthest tip of the the curr root section\n",
        "        lowest_phase = imp_obj.transfer_phase(1)\n",
        "    }\n",
        "\n",
        "    if (curr_subtree_root.nchild != 0) { // if the curr section has child sections\n",
        "        for i=0, curr_subtree_root.nchild-1 curr_subtree_root.child[i] {  // for each child of the root, finds the lowest impedance within the subtree whose root is the curr child (in relation to the proximal tip in the curr root child)\n",
        "            curr_subtree_root.child[i] sref1 = new SectionRef()\n",
        "            lowest_child_subtree_impedance = lowest_impedance_recursive(sref1, imp_obj) // recursively returns the lowest transfer impedance and transfer phase within the curr subtree as a vector\n",
        "            if (lowest_child_subtree_impedance.x[0] < lowest_impedance) {\n",
        "                lowest_impedance = lowest_child_subtree_impedance.x[0]\n",
        "                lowest_phase = lowest_child_subtree_impedance.x[1]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    lowest_imp_vec = new Vector(2)\n",
        "    lowest_imp_vec.x[0] = lowest_impedance\n",
        "    lowest_imp_vec.x[1] = lowest_phase\n",
        "    return lowest_imp_vec\n",
        "}''')\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def push_section(section):\n",
        "    '''push a section onto the top of the NEURON stack, pop it when leaving the context'''\n",
        "    section.push()\n",
        "    yield\n",
        "    h.pop_section()\n",
        "\n",
        "\n",
        "def _get_subtree_biophysical_properties(subtree_root_ref, frequency):\n",
        "    ''' gets the biophysical cable properties (Rm, Ra, Rc) and q\n",
        "\n",
        "    for the subtree to be reduced according to the properties of the root section of the subtree\n",
        "    '''\n",
        "    try:\n",
        "        section = subtree_root_ref.sec\n",
        "    except:\n",
        "        section = subtree_root_ref\n",
        "\n",
        "    rm = 1.0 / section.g_pas  # in ohm * cm^2\n",
        "    # in secs, with conversion of the capacitance from uF/cm2 to F/cm2\n",
        "    RC = rm * (float(section.cm) / 1000000)\n",
        "\n",
        "    # defining q=sqrt(1+iwRC))\n",
        "    angular_freq = 2 * math.pi * frequency   # = w\n",
        "    q_imaginary = angular_freq * RC\n",
        "    q = complex(1, q_imaginary)   # q=1+iwRC\n",
        "    q = cmath.sqrt(q)\t\t# q = sqrt(1+iwRC)\n",
        "\n",
        "    return (section.cm,\n",
        "            rm,\n",
        "            section.Ra,  # in ohm * cm\n",
        "            section.e_pas,\n",
        "            q)\n",
        "\n",
        "\n",
        "def find_lowest_subtree_impedance(subtree_root_ref, imp_obj):\n",
        "    '''\n",
        "    finds the segment in the subtree with the lowest transfer impedance in\n",
        "    relation to the proximal-to-soma end of the given subtree root section,\n",
        "    using a recursive hoc function,\n",
        "\n",
        "    returns the lowest impedance in Ohms\n",
        "    '''\n",
        "    # returns [lowest subtree transfer impedance in Mohms, transfer phase]\n",
        "    lowest_impedance = h.lowest_impedance_recursive(subtree_root_ref, imp_obj)\n",
        "    # impedance saved as a complex number after converting Mohms to ohms\n",
        "    curr_lowest_subtree_imp = cmath.rect(lowest_impedance.x[0] * 1000000, lowest_impedance.x[1])\n",
        "    return curr_lowest_subtree_imp\n",
        "\n",
        "\n",
        "def compute_zl_polar(Z0, L, q):\n",
        "    '''\n",
        "    given Z0 , L and q computes the polar represntation of ZL (equation 2.9 in Gals thesis)\n",
        "    '''\n",
        "    ZL = Z0 * 1.0 / cmath.cosh(q * L)\n",
        "    ZL = cmath.polar(ZL)\n",
        "    return ZL\n",
        "\n",
        "\n",
        "def find_best_real_L(Z0, ZL_goal, q, max_L=10.0, max_depth=50):\n",
        "    '''finds the best real L\n",
        "\n",
        "    s.t. the modulus part of the impedance of ZL in eq 2.9 will be correct\n",
        "    Since the modulus is a decreasing function of L, it is easy to find it using binary search.\n",
        "    '''\n",
        "    min_L = 0.0\n",
        "    current_L = (min_L + max_L) / 2.0\n",
        "    ZL_goal_A = cmath.polar(ZL_goal)[0]\n",
        "\n",
        "    for _ in range(max_depth):\n",
        "        Z_current_L_A = compute_zl_polar(Z0, current_L, q)[0]\n",
        "        if abs(ZL_goal_A - Z_current_L_A) <= 0.001:  # Z are in Ohms , normal values are >10^6\n",
        "            break\n",
        "        elif ZL_goal_A > Z_current_L_A:\n",
        "            current_L, max_L = (min_L + current_L) / 2.0, current_L\n",
        "        else:\n",
        "            current_L, min_L = (max_L + current_L) / 2.0, current_L\n",
        "    else:\n",
        "        logger.info(\"The difference between L and the goal L is larger than 0.001\")\n",
        "    return current_L\n",
        "\n",
        "\n",
        "def compute_zx_polar(Z0, L, q, x):\n",
        "    '''computes the polar represntation of Zx (equation 2.8 in Gals thesis)\n",
        "    '''\n",
        "    ZX = Z0 * cmath.cosh(q * (L - x)) / cmath.cosh(q * L)\n",
        "    ZX = cmath.polar(ZX)\n",
        "    return ZX\n",
        "\n",
        "\n",
        "def find_best_real_X(Z0, ZX_goal, q, L, max_depth=50):\n",
        "    '''finds the best location of a synapse (X)\n",
        "\n",
        "    s.t. the modulus part of the impedance of ZX in eq 2.8 will be correct.\n",
        "    Since the modulus is a decreasing function of L, it is easy to find it using binary search.\n",
        "    '''\n",
        "    min_x, max_x = 0.0, L\n",
        "    current_x = (min_x + max_x) / 2.0\n",
        "\n",
        "    ZX_goal = cmath.polar(ZX_goal)[0]\n",
        "\n",
        "    for _ in range(max_depth):\n",
        "        Z_current_X_A = compute_zx_polar(Z0, L, q, current_x)[0]\n",
        "\n",
        "        if abs(ZX_goal - Z_current_X_A) <= 0.001:\n",
        "            break\n",
        "        elif ZX_goal > Z_current_X_A:\n",
        "            current_x, max_x = (min_x + current_x) / 2.0, current_x\n",
        "        else:\n",
        "            current_x, min_x = (max_x + current_x) / 2.0, current_x\n",
        "    else:\n",
        "        logger.info(\"The difference between X and the goal X is larger than 0.001\")\n",
        "\n",
        "    return current_x\n",
        "\n",
        "\n",
        "def find_subtree_new_electrotonic_length(root_input_impedance, lowest_subtree_impedance, q):\n",
        "    ''' finds the subtree's reduced cable's electrotonic length\n",
        "\n",
        "    based on the following equation:\n",
        "    lowest_subtree_impedance = subtree_root_input_impedance/cosh(q*L)\n",
        "    according to the given complex impedance values\n",
        "    '''\n",
        "\n",
        "    # this equation could be solved analytically using:\n",
        "    # L = 1/q * arcosh(subtree_root_input_impedance/lowest_subtree_impedance),\n",
        "    # But since L in this equation is complex number and we chose to focus on\n",
        "    # finding the correct attenuation\n",
        "    # we decided to search the L that will result with correct attenuation from\n",
        "    # the tip of the dendrite to the soma.\n",
        "    # We chose to use only real L (without a complex part)\n",
        "\n",
        "    L = find_best_real_L(root_input_impedance, lowest_subtree_impedance, q)\n",
        "    return L\n",
        "\n",
        "\n",
        "def _find_subtree_new_diam_in_cm(root_input_impedance, electrotonic_length_as_complex, rm, ra, q):\n",
        "    '''finds the subtree's new cable's diameter (in cm)\n",
        "\n",
        "    according to the given complex input impedance at the segment in the\n",
        "    original subtree that is closest to the soma (the tip), and the given cable\n",
        "    electrotonic length,\n",
        "\n",
        "    with the following equation:\n",
        "    d (in cm) = (2/PI * (sqrt(RM*RA)/(q*subtree_root_input_impedance)) *\n",
        "                 (coth(q * NewCableElectrotonicLength)) )^(2/3)\n",
        "    derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    '''\n",
        "\n",
        "    diam_in_cm = (2.0 / math.pi *\n",
        "                  (math.sqrt(rm * ra) / (q * root_input_impedance)) *\n",
        "                  (1 / cmath.tanh(q * electrotonic_length_as_complex))  # coth = 1/tanh\n",
        "                  ) ** (2.0 / 3)\n",
        "\n",
        "    '''\n",
        "    # for debugging inaccuracies:\n",
        "    if diam_in_cm.imag != 0:\n",
        "        if abs(diam_in_cm.imag) > 0.03:\n",
        "        print \"PROBLEM - DIAM HAS SUBSTANTIAL IMAGINARY PART\"\n",
        "        print \"\\n\"\n",
        "    '''\n",
        "\n",
        "    # the radius of the complex number received from the equation\n",
        "    new_subtree_dend_diam_in_cm = cmath.polar(diam_in_cm)[0]\n",
        "    return new_subtree_dend_diam_in_cm\n",
        "\n",
        "\n",
        "def find_space_const_in_cm(diameter, rm, ra):\n",
        "    ''' returns space constant (lambda) in cm, according to: space_const = sqrt(rm/(ri+r0)) '''\n",
        "    # rm = Rm/(PI * diam), diam is in cm and Rm is in ohm * cm^2\n",
        "    rm = float(rm) / (math.pi * diameter)\n",
        "    # ri = 4*Ra/ (PI * diam^2), diam is in cm and Ra is in ohm * cm\n",
        "    ri = float(4 * ra) / (math.pi * (diameter**2))\n",
        "    space_const = math.sqrt(rm / ri)  # r0 is negligible\n",
        "    return space_const\n",
        "\n",
        "\n",
        "def reduce_subtree(subtree_root, frequency):\n",
        "    '''Reduces the subtree  from the original_cell into one single section (cable).\n",
        "\n",
        "    The reduction is done by finding the length and diameter of the cable (a\n",
        "    single solution) that preserves the subtree's input impedance at the\n",
        "    somatic end, and the transfer impedance in the subtree from the distal end\n",
        "    to the proximal somatic end (between the new cable's two tips).\n",
        "    '''\n",
        "######################################################################\n",
        "    print(subtree_root)\n",
        "##################\n",
        "    subtree_root_ref = h.SectionRef(sec=subtree_root)\n",
        "    cm, rm, ra, e_pas, q = _get_subtree_biophysical_properties(subtree_root_ref, frequency)\n",
        "\n",
        "    # finds the subtree's input impedance (at the somatic-proximal end of the\n",
        "    # subtree root section) and the lowest transfer impedance in the subtree in\n",
        "    # relation to the somatic-proximal end (see more in Readme on NeuroReduce)\n",
        "    imp_obj, root_input_impedance = measure_input_impedance_of_subtree(subtree_root, frequency)\n",
        "\n",
        "    # in Ohms (a complex number)\n",
        "    curr_lowest_subtree_imp = find_lowest_subtree_impedance(subtree_root_ref, imp_obj)\n",
        "\n",
        "    # reducing the whole subtree into one section:\n",
        "    # L = 1/q * arcosh(ZtreeIn(f)/min(ZtreeX,0(f)),\n",
        "    # d = ( (2/pi * (sqrt(Rm*Ra)/q*ZtreeIn(f)) * coth(qL) )^(2/3) - from Gal Eliraz's thesis 1999\n",
        "    new_cable_electrotonic_length = find_subtree_new_electrotonic_length(root_input_impedance,\n",
        "                                                                         curr_lowest_subtree_imp,\n",
        "                                                                         q)\n",
        "    cable_electrotonic_length_as_complex = complex(new_cable_electrotonic_length, 0)\n",
        "    new_cable_diameter_in_cm = _find_subtree_new_diam_in_cm(root_input_impedance,\n",
        "                                                            cable_electrotonic_length_as_complex,\n",
        "                                                            rm,\n",
        "                                                            ra,\n",
        "                                                            q)\n",
        "    new_cable_diameter = new_cable_diameter_in_cm * 10000   # in microns\n",
        "\n",
        "    # calculating the space constant, in order to find the cylinder's length:\n",
        "    # space_const = sqrt(rm/(ri+r0))\n",
        "    curr_space_const_in_cm = find_space_const_in_cm(new_cable_diameter_in_cm,\n",
        "                                                    rm,\n",
        "                                                    ra)\n",
        "    curr_space_const_in_micron = 10000 * curr_space_const_in_cm\n",
        "    new_cable_length = curr_space_const_in_micron * new_cable_electrotonic_length  # in microns\n",
        "\n",
        "    return CableParams(length=new_cable_length,\n",
        "                       diam=new_cable_diameter,\n",
        "                       space_const=curr_space_const_in_micron,\n",
        "                       cm=cm,\n",
        "                       rm=rm,\n",
        "                       ra=ra,\n",
        "                       e_pas=e_pas,\n",
        "                       electrotonic_length=new_cable_electrotonic_length)\n",
        "\n",
        "\n",
        "def find_merged_loc(cable_nseg, relative_loc):\n",
        "    '''\n",
        "    Returns a synapse's merged relative location (x) on the cable, according to\n",
        "    its given relative location on the cable and the given number of segments\n",
        "    in the cable.\n",
        "\n",
        "    The merged location is the relative location of the middle of the segment\n",
        "    the synapse is in (or 0 or 1 if it is at one of the tips of the cable).\n",
        "    '''\n",
        "\n",
        "    if relative_loc in (0, 1):\n",
        "        return relative_loc\n",
        "\n",
        "    # finds the segment that the synapse is in, according to its relative\n",
        "    # location and the num of segments in the cable (1 through nseg)\n",
        "    mapped_segment_for_curr_syn = int(relative_loc * cable_nseg) + 1\n",
        "\n",
        "    # location of middle of segment = the average between relative location of\n",
        "    # end of segment and relative location of beginning of segment\n",
        "    return ((float(mapped_segment_for_curr_syn) / cable_nseg) +\n",
        "            (float(mapped_segment_for_curr_syn - 1) / cable_nseg)) / 2\n",
        "\n",
        "\n",
        "def measure_input_impedance_of_subtree(subtree_root_section, frequency):\n",
        "    '''measures the input impedance of the subtree with the given root section\n",
        "\n",
        "    (at the \"0\" tip, the soma-proximal end),\n",
        "    returns the Impedance hoc object and the input impedance as a complex value\n",
        "    '''\n",
        "\n",
        "    imp_obj = h.Impedance()\n",
        "    CLOSE_TO_SOMA_EDGE = 0\n",
        "    # sets origin for impedance calculations (soma-proximal end of root section)\n",
        "    imp_obj.loc(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section)\n",
        "\n",
        "    # computes transfer impedance from every segment in the model in relation\n",
        "    # to the origin location above\n",
        "    imp_obj.compute(frequency + 1 / 9e9, 0)\n",
        "\n",
        "    # in Ohms (impedance measured at soma-proximal end of root section)\n",
        "    root_input_impedance = imp_obj.input(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section) * 1000000\n",
        "    root_input_phase = imp_obj.input_phase(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section)\n",
        "    # creates a complex impedance value out of the given polar coordinates\n",
        "    root_input_impedance = cmath.rect(root_input_impedance, root_input_phase)\n",
        "    return imp_obj, root_input_impedance\n",
        "\n",
        "\n",
        "def reduce_synapse(cell_instance,\n",
        "                   synapse_location,\n",
        "                   on_basal,\n",
        "                   imp_obj,\n",
        "                   root_input_impedance,\n",
        "                   new_cable_electrotonic_length,\n",
        "                   q_subtree):\n",
        "    '''\n",
        "    Receives an instance of a cell, the location (section + relative\n",
        "    location(x)) of a synapse to be reduced, a boolean on_basal that is True if\n",
        "    the synapse is on a basal subtree, the number of segments in the reduced\n",
        "    cable that this synapse is in, an Impedance calculating Hoc object, the\n",
        "    input impedance at the root of this subtree, and the electrotonic length of\n",
        "    the reduced cable that represents the current subtree\n",
        "    (as a real and as a complex number) -\n",
        "    and maps the given synapse to its new location on the reduced cable\n",
        "    according to the NeuroReduce algorithm.  Returns the new \"post-merging\"\n",
        "    relative location of the synapse on the reduced cable (x, 0<=x<=1), that\n",
        "    represents the middle of the segment that this synapse is located at in the\n",
        "    new reduced cable.\n",
        "    '''\n",
        "    # measures the original transfer impedance from the synapse to the\n",
        "    # somatic-proximal end in the subtree root section\n",
        "    if not on_basal:  # apical subtree\n",
        "        section = cell_instance.apic[synapse_location.section_num]\n",
        "    else:             # basal subtree\n",
        "        section = cell_instance.dend[synapse_location.section_num]\n",
        "\n",
        "    with push_section(section):\n",
        "        orig_transfer_imp = imp_obj.transfer(synapse_location.x) * 1000000  # ohms\n",
        "        orig_transfer_phase = imp_obj.transfer_phase(synapse_location.x)\n",
        "        # creates a complex Impedance value with the given polar coordinates\n",
        "        orig_synapse_transfer_impedance = cmath.rect(orig_transfer_imp, orig_transfer_phase)\n",
        "\n",
        "    # synapse location could be calculated using:\n",
        "    # X = L - (1/q) * arcosh( (Zx,0(f) / ZtreeIn(f)) * cosh(q*L) ),\n",
        "    # derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    # but we chose to find the X that will give the correct modulus. See comment about L values\n",
        "\n",
        "    synapse_new_electrotonic_location = find_best_real_X(root_input_impedance,\n",
        "                                                         orig_synapse_transfer_impedance,\n",
        "                                                         q_subtree,\n",
        "                                                         new_cable_electrotonic_length)\n",
        "                                                         \n",
        "    new_relative_loc_in_section = (float(synapse_new_electrotonic_location) /\n",
        "                                   new_cable_electrotonic_length)\n",
        "\n",
        "    if new_relative_loc_in_section > 1:  # PATCH\n",
        "        new_relative_loc_in_section = 0.999999\n",
        "\n",
        "    return new_relative_loc_in_section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rrl9PrfgKVc"
      },
      "source": [
        "subtree_reductor_func.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldkLMJxNgKAl"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "function subtree_reductor():\n",
        " which reduces a morphologically detailed cell instance into a morphologically\n",
        " simplified cell instance, according to NeuroReduce and merges synapses of the\n",
        " same type (same reverse potential, tau1, and tau2) that are mapped to the same\n",
        " segment. (see more in Readme on tool and usage)\n",
        " usage: For details, see comments in function\n",
        " outputs: reduced cell instance, a new synapses_list, and the netcons_list,\n",
        "          which now corresponds to the new synapses.\n",
        "- The model template file must have an init() function (see example in the\n",
        "  attached model.hoc file) and the following public definitions specifying\n",
        "  sections and section lists accordingly:\n",
        "   public soma, dend, apic ; public all, somatic, apical, basal\n",
        "- Supports numerous types of synapses (two synapses are considered to be of\n",
        "  different types if they are different from each other in at least one of the\n",
        "  following values: reverse potential, tau1, tau2)\n",
        "'''\n",
        "import collections\n",
        "import itertools as it\n",
        "import logging\n",
        "import math\n",
        "import re\n",
        "import cmath\n",
        "\n",
        "import numpy as np\n",
        "import neuron\n",
        "from neuron import h\n",
        "h.load_file(\"stdrun.hoc\")\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "SOMA_LABEL = \"soma\"\n",
        "EXCLUDE_MECHANISMS = ('pas', 'na_ion', 'k_ion', 'ca_ion', 'h_ion', 'ttx_ion', )\n",
        "\n",
        "\n",
        "def create_sections_in_hoc(type_of_section, num, instance_as_str):\n",
        "    '''creates sections in the hoc world according to the given section type and number of sections\n",
        "    in the instance whose name is given as a string\n",
        "    '''\n",
        "    h(\"strdef string\")\n",
        "    h.string = type_of_section\n",
        "    h('{sprint(string, \"create %s[%d]\", string, ' + str(num) + ') }')\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "\n",
        "\n",
        "def append_to_section_lists(section, type_of_sectionlist, instance_as_str):\n",
        "    ''' appends given section to the sectionlist of the given type and to the \"all\" sectionlist\n",
        "    in the hoc world in the instance whose name is given as a string\n",
        "    '''\n",
        "    h(\"strdef string\")\n",
        "    print('trying to append:',section)\n",
        "    h.string = section + \" \" + type_of_sectionlist + \".append()\"\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "    h.string = section + \" all.append()\"\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "\n",
        "\n",
        "def find_section_number(section):\n",
        "    ''' extracts and returns the section number from the given section object '''\n",
        "    sec_name = h.secname(sec=section)\n",
        "    ints_in_name = re.findall(r'\\d+', sec_name)\n",
        "    sec_num = ints_in_name[len(ints_in_name) - 1]  # extracts section number\n",
        "    return sec_num\n",
        "\n",
        "\n",
        "def calculate_nsegs_from_manual_arg(new_cable_properties, total_segments_wanted):\n",
        "    '''Calculates the number of segments for each section in the reduced model\n",
        "    according to the given total_segments_wanted and the given\n",
        "    new_dends_electrotonic_length (the electrotonic lengths of all the new\n",
        "    sections).  Called when the user chooses to give to the program the\n",
        "    approximate total number of segments that the reduced model should have\n",
        "    (non-default calculation).\n",
        "    '''\n",
        "    # minus one for the one segment of the soma:\n",
        "    total_segments_in_dendrites = total_segments_wanted - 1\n",
        "\n",
        "    # total electrotonic length of reduced dendritic cables\n",
        "    sum_of_lengths = sum(prop.electrotonic_length\n",
        "                         for prop in new_cable_properties)\n",
        "\n",
        "    # the num of segments assigned to each section is in proportion to the\n",
        "    # section's relative contribution to the total electrotonic length in the\n",
        "    # model\n",
        "    dends_nsegs = []\n",
        "    for prop in new_cable_properties:\n",
        "        new_length = prop.electrotonic_length\n",
        "        new_nseg_to_put = int(round((float(new_length) / sum_of_lengths) *\n",
        "                              total_segments_in_dendrites))\n",
        "        if new_nseg_to_put < 1:\n",
        "            new_nseg_to_put = 1\n",
        "        dends_nsegs.append(new_nseg_to_put)\n",
        "    return dends_nsegs\n",
        "\n",
        "\n",
        "def calculate_nsegs_from_lambda(new_cable_properties):\n",
        "    '''calculate the number of segments for each section in the reduced model\n",
        "    according to the length (in microns) and space constant (= lambda - in\n",
        "    microns) that were previously calculated for each section and are given in\n",
        "    subtree_dimensions.  According to this calculation, a segment is formed for\n",
        "    every 0.1 * lambda in a section. (lambda = space constant = electrotonic length unit).\n",
        "    '''\n",
        "    dends_nsegs = []\n",
        "    for cable in new_cable_properties:\n",
        "        # for every unit of electronic length (length/space_constant such units)\n",
        "        # ~10 segments are formed\n",
        "        dends_nsegs.append(int((float(cable.length) / cable.space_const) * 10 / 2) * 2 + 1)\n",
        "    return dends_nsegs\n",
        "\n",
        "\n",
        "def mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                             section_per_subtree_index,\n",
        "                                             root_sec_of_subtree,\n",
        "                                             mapping_sections_to_subtree_index,\n",
        "                                             section_type,\n",
        "                                             subtree_index):\n",
        "    '''Recursively marks all sections in the subtree as belonging to the given subtree_index\n",
        "    using the given dict mapping_sections_to_subtree_index, as follows:\n",
        "    mapping_sections_to_subtree_index[(<section_type>, <section_number>)] = given subtree_index\n",
        "    '''\n",
        "    sections_to_delete.append(root_sec_of_subtree)\n",
        "    section_per_subtree_index.setdefault(subtree_index, [])\n",
        "    section_per_subtree_index[subtree_index].append(root_sec_of_subtree)\n",
        "\n",
        "    section_num = find_section_number(root_sec_of_subtree)\n",
        "\n",
        "    for child in root_sec_of_subtree.children():\n",
        "        mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                 section_per_subtree_index,\n",
        "                                                 child,\n",
        "                                                 mapping_sections_to_subtree_index,\n",
        "                                                 section_type,\n",
        "                                                 subtree_index)\n",
        "    mapping_sections_to_subtree_index[(section_type, section_num)] = subtree_index\n",
        "\n",
        "\n",
        "def find_synapse_loc(synapse_or_segment, mapping_sections_to_subtree_index):\n",
        "    ''' Returns the location  of the given synapse object'''\n",
        "\n",
        "    if not isinstance(synapse_or_segment, neuron.nrn.Segment):\n",
        "        synapse_or_segment = synapse_or_segment.get_segment()\n",
        "\n",
        "    x = synapse_or_segment.x\n",
        "\n",
        "    with push_section(synapse_or_segment.sec):\n",
        "        # extracts the section type (\"soma\", \"apic\", \"dend\") and the section number\n",
        "        # out of the section name\n",
        "        full_sec_name = h.secname()\n",
        "        sec_name_as_list = full_sec_name.split(\".\")\n",
        "        short_sec_name = sec_name_as_list[len(sec_name_as_list) - 1]\n",
        "        section_type = short_sec_name.split(\"[\")[0]\n",
        "        section_num = re.findall(r'\\d+', short_sec_name)[0]\n",
        "\n",
        "    # finds the index of the subtree that this synapse belongs to using the\n",
        "    # given mapping_sections_to_subtree_index which maps sections to the\n",
        "    # subtree indexes that they belong to\n",
        "    print(mapping_sections_to_subtree_index)\n",
        "    if section_type == \"apic\":\n",
        "        subtree_index = mapping_sections_to_subtree_index[(\"apic\", section_num)]\n",
        "    elif section_type == \"dend\":\n",
        "        subtree_index = mapping_sections_to_subtree_index[(\"basal\", section_num)]\n",
        "    else:  # somatic synapse\n",
        "        subtree_index, section_num, x = SOMA_LABEL, 0, 0\n",
        "\n",
        "    return SynapseLocation(subtree_index, int(section_num), x)\n",
        "\n",
        "\n",
        "def find_and_disconnect_axon(soma_ref):\n",
        "    '''Searching for an axon, it can be a child of the soma or a parent of the soma.'''\n",
        "    axon_section, axon_parent, soma_axon_x  = [], False, None\n",
        "\n",
        "    for sec in soma_ref.child:\n",
        "        name = sec.hname().lower()\n",
        "        if 'axon' in name or 'hill' in name:\n",
        "            axon_section.append(sec)\n",
        "            # disconnect axon\n",
        "            soma_axon_x = sec.parentseg().x\n",
        "            sec.push()\n",
        "            h.disconnect()\n",
        "            h.define_shape()\n",
        "\n",
        "    if soma_ref.has_parent():\n",
        "        name = soma_ref.parent().sec.hname().lower()\n",
        "        if 'axon' in name or 'hill' in name:\n",
        "            axon_section.append(soma_ref.parent())\n",
        "            axon_parent = True\n",
        "            soma_axon_x = None\n",
        "            soma_ref.push()\n",
        "            h.disconnect()\n",
        "        else:\n",
        "            raise Exception('Soma has a parent which is not an axon')\n",
        "\n",
        "    if len(axon_section) > 1:\n",
        "        raise Exception('Soma has a two axons')\n",
        "\n",
        "    return axon_section, axon_parent, soma_axon_x\n",
        "\n",
        "\n",
        "def create_segments_to_mech_vals(sections_to_delete,\n",
        "                                 remove_mechs=True,\n",
        "                                 exclude=EXCLUDE_MECHANISMS):\n",
        "    '''This function copy the create a mapping between a dictionary and the mechanisms that it have\n",
        "       plus the values of those mechanisms. It also remove the mechanisms from the model in order to\n",
        "       create a passive model\n",
        "       Arguments:\n",
        "           remove_mechs - False|True\n",
        "               if True remove the mechs after creating the mapping, False - keep the mechs\n",
        "           exclude - List of all the mechs name that should not be removed\n",
        "       '''\n",
        "    exclude = set(exclude)\n",
        "    segment_to_mech_vals, mech_names = {}, set()\n",
        "    for seg in it.chain.from_iterable(sections_to_delete):\n",
        "        segment_to_mech_vals[seg] = {}\n",
        "        for mech in seg:\n",
        "            mech_name = mech.name()\n",
        "            segment_to_mech_vals[seg][mech_name] = {}\n",
        "            for n in dir(mech):\n",
        "                if n.startswith('__') or n in ('next', 'name', 'is_ion', 'segment', ):\n",
        "                    continue\n",
        "\n",
        "                if not n.endswith('_' + mech_name) and not mech_name.endswith('_ion'):\n",
        "                    n += '_' + mech_name\n",
        "\n",
        "                segment_to_mech_vals[seg][mech_name][n] = getattr(seg, n)\n",
        "                mech_names.add(mech_name)\n",
        "\n",
        "    mech_names -= exclude\n",
        "\n",
        "    if remove_mechs:  # Remove all the mechs from the sections\n",
        "        for sec in sections_to_delete:\n",
        "            with push_section(sec):\n",
        "                for mech in mech_names:\n",
        "                    h(\"uninsert \" + mech)\n",
        "\n",
        "    return segment_to_mech_vals\n",
        "\n",
        "\n",
        "def create_seg_to_seg(original_cell,\n",
        "                      section_per_subtree_index,\n",
        "                      roots_of_subtrees,\n",
        "                      mapping_sections_to_subtree_index,\n",
        "                      new_cable_properties,\n",
        "                      has_apical,\n",
        "                      apic,\n",
        "                      basals,\n",
        "                      subtree_ind_to_q,\n",
        "                      mapping_type,\n",
        "                      reduction_frequency):\n",
        "    '''create mapping between segments in the original model to segments in the reduced model\n",
        "       if mapping_type == impedance the mapping will be a response to the\n",
        "       transfer impedance of each segment to the soma (like the synapses)\n",
        "       if mapping_type == distance  the mapping will be a response to the\n",
        "       distance of each segment to the soma (like the synapses) NOT IMPLEMENTED\n",
        "       YET\n",
        "       '''\n",
        "\n",
        "    assert mapping_type == 'impedance', 'distance mapping not implemented yet'\n",
        "    # the keys are the segments of the original model, the values are the\n",
        "    # segments of the reduced model\n",
        "    original_seg_to_reduced_seg = {}\n",
        "    reduced_seg_to_original_seg = collections.defaultdict(list)\n",
        "    for subtree_index in section_per_subtree_index:\n",
        "        for sec in section_per_subtree_index[subtree_index]:\n",
        "            for seg in sec:\n",
        "                synapse_location = find_synapse_loc(seg, mapping_sections_to_subtree_index)\n",
        "                imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "                    roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "\n",
        "                # if synapse is on the apical subtree\n",
        "                on_basal_subtree = not (has_apical and subtree_index == 0)\n",
        "\n",
        "                mid_of_segment_loc = reduce_synapse(\n",
        "                    original_cell,\n",
        "                    synapse_location,\n",
        "                    on_basal_subtree,\n",
        "                    imp_obj,\n",
        "                    subtree_input_impedance,\n",
        "                    new_cable_properties[subtree_index].electrotonic_length,\n",
        "                    subtree_ind_to_q[subtree_index])\n",
        "\n",
        "                if on_basal_subtree:\n",
        "                    if has_apical:\n",
        "                        new_section_for_synapse = basals[subtree_index - 1]\n",
        "                    else:\n",
        "                        new_section_for_synapse = basals[subtree_index]\n",
        "                else:\n",
        "                    new_section_for_synapse = apic\n",
        "\n",
        "                reduced_seg = new_section_for_synapse(mid_of_segment_loc)\n",
        "                original_seg_to_reduced_seg[seg] = reduced_seg\n",
        "                reduced_seg_to_original_seg[reduced_seg].append(seg)\n",
        "\n",
        "    return original_seg_to_reduced_seg, dict(reduced_seg_to_original_seg)\n",
        "\n",
        "\n",
        "def copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type='impedance'):\n",
        "    ''' copies the mechanisms from the original model to the reduced model'''\n",
        "\n",
        "    # copy mechanisms\n",
        "    # this is needed for the case where some segements were not been mapped\n",
        "    mech_names_per_segment = collections.defaultdict(list)\n",
        "    vals_per_mech_per_segment = {}\n",
        "    for reduced_seg, original_segs in reduced_seg_to_original_seg.items():\n",
        "        vals_per_mech_per_segment[reduced_seg] = collections.defaultdict(list)\n",
        "\n",
        "        for original_seg in original_segs:\n",
        "            for mech_name, mech_params in segment_to_mech_vals[original_seg].items():\n",
        "                for param_name, param_value in mech_params.items():\n",
        "                    vals_per_mech_per_segment[reduced_seg][param_name].append(param_value)\n",
        "\n",
        "                mech_names_per_segment[reduced_seg].append(mech_name)\n",
        "                reduced_seg.sec.insert(mech_name)\n",
        "\n",
        "        for param_name, param_values in vals_per_mech_per_segment[reduced_seg].items():\n",
        "            setattr(reduced_seg, param_name, np.mean(param_values))\n",
        "\n",
        "    all_segments = []\n",
        "    if apic is not None:\n",
        "        all_segments.extend(list(apic))\n",
        "\n",
        "    for bas in basals:\n",
        "        all_segments.extend(list(bas))\n",
        "\n",
        "    if len(all_segments) != len(reduced_seg_to_original_seg):\n",
        "        logger.warning('There is no segment to segment copy, it means that some segments in the'\n",
        "                    'reduced model did not receive channels from the original cell.'\n",
        "                    'Trying to compensate by copying channels from neighboring segments')\n",
        "        handle_orphan_segments(original_seg_to_reduced_seg,\n",
        "                               all_segments,\n",
        "                               vals_per_mech_per_segment,\n",
        "                               mech_names_per_segment)\n",
        "\n",
        "\n",
        "def handle_orphan_segments(original_seg_to_reduced_seg,\n",
        "                           all_segments,\n",
        "                           vals_per_mech_per_segment,\n",
        "                           mech_names_per_segment):\n",
        "    ''' This function handle reduced segments that did not had original segments mapped to them'''\n",
        "    # Get all reduced segments that have been mapped by a original model segment\n",
        "    all_mapped_control_segments = original_seg_to_reduced_seg.values()\n",
        "    non_mapped_segments = set(all_segments) - set(all_mapped_control_segments)\n",
        "\n",
        "    for reduced_seg in non_mapped_segments:\n",
        "        seg_secs = list(reduced_seg.sec)\n",
        "        # find valid parent\n",
        "        parent_seg_index = seg_secs.index(reduced_seg) - 1\n",
        "        parent_seg = None\n",
        "        while parent_seg_index > -1:\n",
        "            if seg_secs[parent_seg_index] in all_mapped_control_segments:\n",
        "                parent_seg = seg_secs[parent_seg_index]\n",
        "                break\n",
        "            else:\n",
        "                parent_seg_index -= 1\n",
        "\n",
        "        # find valid child\n",
        "        child_seg_index = seg_secs.index(reduced_seg) + 1\n",
        "        child_seg = None\n",
        "        while child_seg_index < len(seg_secs):\n",
        "            if seg_secs[child_seg_index] in all_mapped_control_segments:\n",
        "                child_seg = seg_secs[child_seg_index]\n",
        "                break\n",
        "            else:\n",
        "                child_seg_index += 1\n",
        "\n",
        "        if not parent_seg and not child_seg:\n",
        "            raise Exception(\"no child seg nor parent seg, with active channels, was found\")\n",
        "\n",
        "        if parent_seg and not child_seg:\n",
        "            for mech in mech_names_per_segment[parent_seg]:\n",
        "                reduced_seg.sec.insert(mech)\n",
        "            for n in vals_per_mech_per_segment[parent_seg]:\n",
        "                setattr(reduced_seg, n, np.mean(vals_per_mech_per_segment[parent_seg][n]))\n",
        "\n",
        "        if not parent_seg and child_seg:\n",
        "            for mech in mech_names_per_segment[child_seg]:\n",
        "                reduced_seg.sec.insert(mech)\n",
        "            for n in vals_per_mech_per_segment[child_seg]:\n",
        "                setattr(reduced_seg, n, np.mean(vals_per_mech_per_segment[child_seg][n]))\n",
        "\n",
        "        # if both parent and child were found, we add to the segment all the mech in both\n",
        "        # this is just a decision\n",
        "\n",
        "        if parent_seg and child_seg:\n",
        "            for mech in set(mech_names_per_segment[child_seg]) & set(mech_names_per_segment[parent_seg]):\n",
        "                reduced_seg.sec.insert(mech)\n",
        "\n",
        "            for n in vals_per_mech_per_segment[child_seg]:\n",
        "                child_mean = np.mean(vals_per_mech_per_segment[child_seg][n])\n",
        "                if n in vals_per_mech_per_segment[parent_seg]:\n",
        "                    parent_mean = np.mean(vals_per_mech_per_segment[parent_seg][n])\n",
        "                    setattr(reduced_seg, n, (child_mean + parent_mean) / 2)\n",
        "                else:\n",
        "                    setattr(reduced_seg, n, child_mean)\n",
        "\n",
        "            for n in vals_per_mech_per_segment[parent_seg]:\n",
        "                parent_mean = np.mean(vals_per_mech_per_segment[parent_seg][n])\n",
        "                if n in vals_per_mech_per_segment[child_seg]:\n",
        "                    child_mean = np.mean(vals_per_mech_per_segment[child_seg][n])\n",
        "                    setattr(reduced_seg, n, (child_mean + parent_mean) / 2)\n",
        "                else:\n",
        "                    setattr(reduced_seg, n, parent_mean)\n",
        "\n",
        "\n",
        "def add_PP_properties_to_dict(PP, PP_params_dict):\n",
        "    '''\n",
        "    add the propeties of a point process to PP_params_dict.\n",
        "    The only propeties added to the dictionary are those worth comparing\n",
        "    '''\n",
        "    skipped_params = {\"Section\", \"allsec\", \"baseattr\", \"cas\", \"g\", \"get_loc\", \"has_loc\", \"hname\",\n",
        "                      'hocobjptr', \"i\", \"loc\", \"next\", \"ref\", \"same\", \"setpointer\", \"state\",\n",
        "                      \"get_segment\",\n",
        "                      }\n",
        "    PP_params = []\n",
        "    for param in dir(PP):\n",
        "        if param.startswith(\"__\") or param in skipped_params:\n",
        "            continue\n",
        "        PP_params.append(param)\n",
        "    PP_params_dict[type_of_point_process(PP)] = PP_params\n",
        "\n",
        "\n",
        "def type_of_point_process(PP):\n",
        "    s = PP.hname()\n",
        "    ix = PP.hname().find(\"[\")\n",
        "    return s[:ix]\n",
        "\n",
        "\n",
        "def apply_params_to_section(name, type_of_sectionlist, instance_as_str, section, cable_params, nseg):\n",
        "    section.L = cable_params.length\n",
        "    section.diam = cable_params.diam\n",
        "    section.nseg = nseg\n",
        "\n",
        "    append_to_section_lists(name, type_of_sectionlist, instance_as_str)\n",
        "\n",
        "    section.insert('pas')\n",
        "    section.cm = cable_params.cm\n",
        "    section.g_pas = 1.0 / cable_params.rm\n",
        "    section.Ra = cable_params.ra\n",
        "    section.e_pas = cable_params.e_pas\n",
        "\n",
        "\n",
        "def calculate_subtree_q(root, reduction_frequency):\n",
        "    rm = 1.0 / root.g_pas\n",
        "    rc = rm * (float(root.cm) / 1000000)\n",
        "    angular_freq = 2 * math.pi * reduction_frequency\n",
        "    q_imaginary = angular_freq * rc\n",
        "    q_subtree = complex(1, q_imaginary)   # q=1+iwRC\n",
        "    q_subtree = cmath.sqrt(q_subtree)\n",
        "    return q_subtree\n",
        "\n",
        "\n",
        "def synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "    if PP.hname()[:PP.hname().rindex('[')] != synapse.hname()[:synapse.hname().rindex('[')]:\n",
        "        return False\n",
        "    for param in PP_params_dict[type_of_point_process(PP)]:\n",
        "        if(param not in ['rng'] and  # https://github.com/neuronsimulator/nrn/issues/136\n",
        "           str(type(getattr(PP, param))) != \"<type 'hoc.HocObject'>\" and  # ignore hoc objects\n",
        "           getattr(PP, param) != getattr(synapse, param)):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def load_model(model_filename):\n",
        "    model_obj_name = model_filename.split(\".\")[0].split('/')[-1]\n",
        "    if h.name_declared(model_obj_name) == 0:\n",
        "        logger.debug(\"loading template '%s'\" % model_obj_name)\n",
        "        if model_filename == 'model.hoc':\n",
        "            logger.debug(\"loading default reduced model\")\n",
        "            load_default_model()\n",
        "        else:\n",
        "            h.load_file(model_filename)\n",
        "    else:\n",
        "        logger.info(\"The template '%s' is already defined... not loading.\" % model_obj_name)\n",
        "    return model_obj_name\n",
        "\n",
        "\n",
        "def gather_subtrees(soma_ref):\n",
        "    '''get all the subtrees of the soma\n",
        "    assumes the axon is already disconnected\n",
        "    return (list(roots_of_subtrees), list(num_of_subtrees))\n",
        "    where:\n",
        "      roots_of_subtrees holds the root sections of each of the soma's subtrees\n",
        "        note: The apical, if it exists, has been moved to the front\n",
        "      num_of_subtrees correctly the number of subtrees, excluding the axon\n",
        "    '''\n",
        "\n",
        "    roots_of_subtrees = []\n",
        "    num_of_subtrees = []\n",
        "    for i in range(int(soma_ref.nchild())):\n",
        "        if 'soma' in str(soma_ref.child[i]):\n",
        "            logger.warning(\"soma is child, ignore - not tested yet\")\n",
        "            continue\n",
        "        num_of_subtrees.append(i)\n",
        "        roots_of_subtrees.append(soma_ref.child[i])\n",
        "\n",
        "    # assuming up to one apical tree\n",
        "    ix_of_apical = None\n",
        "    for i in num_of_subtrees:\n",
        "        if 'apic' in roots_of_subtrees[i].hname():\n",
        "            assert ix_of_apical is None, 'Multiple apical dendrites not supported'\n",
        "            ix_of_apical = i\n",
        "\n",
        "    if ix_of_apical is not None:\n",
        "        roots_of_subtrees = ([roots_of_subtrees[ix_of_apical]] +\n",
        "                             roots_of_subtrees[:ix_of_apical] +\n",
        "                             roots_of_subtrees[ix_of_apical + 1:])\n",
        "    return roots_of_subtrees, num_of_subtrees\n",
        "\n",
        "\n",
        "def gather_cell_subtrees(roots_of_subtrees):\n",
        "    # dict that maps section indexes to the subtree index they are in: keys are\n",
        "    # string tuples: (\"apic\"/\"basal\", orig_section_index) , values are ints:\n",
        "    # subtree_instance_index\n",
        "    sections_to_delete = []\n",
        "    section_per_subtree_index = {}\n",
        "    mapping_sections_to_subtree_index = {}\n",
        "    for i, soma_child in enumerate(roots_of_subtrees):\n",
        "        # inserts each section in this subtree into the above dict, which maps\n",
        "        # it to the subtree index\n",
        "        if 'apic' in soma_child.hname():\n",
        "            assert i == 0, ('The apical is not the first child of the soma! '\n",
        "                            'a code refactoring is needed in order to accept it')\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"apic\",\n",
        "                                                     i)\n",
        "        elif 'dend' in soma_child.hname() or 'basal' in soma_child.hname():\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"basal\",\n",
        "                                                     i)\n",
        "\n",
        "    return sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index\n",
        "\n",
        "\n",
        "def create_reduced_cell(soma_cable,\n",
        "                        has_apical,\n",
        "                        original_cell,\n",
        "                        model_obj_name,\n",
        "                        new_cable_properties,\n",
        "                        new_cables_nsegs,\n",
        "                        subtrees_xs):\n",
        "    h(\"objref reduced_cell\")\n",
        "    h(\"reduced_cell = new \" + model_obj_name + \"()\")\n",
        "\n",
        "    create_sections_in_hoc(\"soma\", 1, \"reduced_cell\")\n",
        "\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "    append_to_section_lists(\"soma[0]\", \"somatic\", \"reduced_cell\")\n",
        "\n",
        "    if has_apical:  # creates reduced apical cable if apical subtree existed\n",
        "        create_sections_in_hoc(\"apic\", 1, \"reduced_cell\")\n",
        "        apic = h.reduced_cell.apic[0]\n",
        "        num_of_basal_subtrees = len(new_cable_properties) - 1\n",
        "\n",
        "        cable_params = new_cable_properties[0]\n",
        "        nseg = new_cables_nsegs[0]\n",
        "        apply_params_to_section(\"apic[0]\", \"apical\", \"reduced_cell\",\n",
        "                                apic, cable_params, nseg)\n",
        "        apic.connect(soma, subtrees_xs[0], 0)\n",
        "    else:\n",
        "        apic = None\n",
        "        num_of_basal_subtrees = len(new_cable_properties)\n",
        "\n",
        "    # creates reduced basal cables\n",
        "    create_sections_in_hoc(\"dend\", num_of_basal_subtrees, \"reduced_cell\")\n",
        "    basals = [h.reduced_cell.dend[i] for i in range(num_of_basal_subtrees)]\n",
        "\n",
        "    for i in range(num_of_basal_subtrees):\n",
        "        if has_apical:\n",
        "            index_in_reduced_cables_dimensions = i + 1\n",
        "        else:\n",
        "            index_in_reduced_cables_dimensions = i\n",
        "\n",
        "        cable_params = new_cable_properties[index_in_reduced_cables_dimensions]\n",
        "        nseg = new_cables_nsegs[index_in_reduced_cables_dimensions]\n",
        "\n",
        "        apply_params_to_section(\"dend[\" + str(i) + \"]\", \"basal\", \"reduced_cell\",\n",
        "                                basals[i], cable_params, nseg)\n",
        "\n",
        "        basals[i].connect(soma, subtrees_xs[index_in_reduced_cables_dimensions], 0)\n",
        "\n",
        "    # create cell python template\n",
        "    cell = Neuron(h.reduced_cell)\n",
        "    cell.soma = original_cell.soma\n",
        "    cell.apic = apic\n",
        "\n",
        "    return cell, basals\n",
        "\n",
        "\n",
        "def merge_and_add_synapses(num_of_subtrees,\n",
        "                           new_cable_properties,\n",
        "                           PP_params_dict,\n",
        "                           synapses_list,\n",
        "                           mapping_sections_to_subtree_index,\n",
        "                           netcons_list,\n",
        "                           has_apical,\n",
        "                           roots_of_subtrees,\n",
        "                           original_cell,\n",
        "                           basals,\n",
        "                           cell,\n",
        "                           reduction_frequency):\n",
        "    # dividing the original synapses into baskets, so that all synapses that are\n",
        "    # on the same subtree will be together in the same basket\n",
        "\n",
        "    # a list of baskets of synapses, each basket in the list will hold the\n",
        "    # synapses of the subtree of the corresponding basket index\n",
        "    baskets = [[] for _ in num_of_subtrees]\n",
        "    soma_synapses_syn_to_netcon = {}\n",
        "\n",
        "    for syn_index, synapse in enumerate(synapses_list):\n",
        "        synapse_location = find_synapse_loc(synapse, mapping_sections_to_subtree_index)\n",
        "\n",
        "        # for a somatic synapse\n",
        "        # TODO: 'axon' is never returned by find_synapse_loc...\n",
        "        if synapse_location.subtree_index in (SOMA_LABEL, 'axon'):\n",
        "            soma_synapses_syn_to_netcon[synapse] = netcons_list[syn_index]\n",
        "        else:\n",
        "            baskets[synapse_location.subtree_index].append((synapse, synapse_location, syn_index))\n",
        "\n",
        "    # mapping (non-somatic) synapses to their new location on the reduced model\n",
        "    # (the new location is the exact location of the middle of the segment they\n",
        "    # were mapped to, in order to enable merging)\n",
        "    new_synapses_list, subtree_ind_to_q = [], {}\n",
        "    for subtree_index in num_of_subtrees:\n",
        "        imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "            roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "        subtree_ind_to_q[subtree_index] = calculate_subtree_q(\n",
        "            roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "\n",
        "        # iterates over the synapses in the curr basket\n",
        "        for synapse, synapse_location, syn_index in baskets[subtree_index]:\n",
        "            on_basal_subtree = not (has_apical and subtree_index == 0)\n",
        "\n",
        "            # \"reduces\" the synapse - finds this synapse's new \"merged\"\n",
        "            # location on its corresponding reduced cable\n",
        "            x = reduce_synapse(original_cell,\n",
        "                               synapse_location,\n",
        "                               on_basal_subtree,\n",
        "                               imp_obj,\n",
        "                               subtree_input_impedance,\n",
        "                               new_cable_properties[subtree_index].electrotonic_length,\n",
        "                               subtree_ind_to_q[subtree_index])\n",
        "\n",
        "            # find the section of the synapse\n",
        "            if on_basal_subtree:\n",
        "                if has_apical:\n",
        "                    section_for_synapse = basals[subtree_index - 1]\n",
        "                else:\n",
        "                    section_for_synapse = basals[subtree_index]\n",
        "            else:\n",
        "                section_for_synapse = cell.apic\n",
        "\n",
        "            # go over all point processes in this segment and see whether one\n",
        "            # of them has the same proporties of this synapse\n",
        "            # If there's such a synapse link the original NetCon with this point processes\n",
        "            # If not, move the synapse to this segment.\n",
        "            for PP in section_for_synapse(x).point_processes():\n",
        "                if type_of_point_process(PP) not in PP_params_dict:\n",
        "                    add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "                if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                    netcons_list[syn_index].setpost(PP)\n",
        "                    break\n",
        "            else:  # If for finish the loop -> first appearance of this synapse\n",
        "                synapse.loc(x, sec=section_for_synapse)\n",
        "                new_synapses_list.append(synapse)\n",
        "\n",
        "    # merging somatic and axonal synapses\n",
        "    synapses_per_seg = collections.defaultdict(list)\n",
        "    for synapse in soma_synapses_syn_to_netcon:\n",
        "        seg_pointer = synapse.get_segment()\n",
        "\n",
        "        for PP in synapses_per_seg[seg_pointer]:\n",
        "            if type_of_point_process(PP) not in PP_params_dict:\n",
        "                add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "            if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                soma_synapses_syn_to_netcon[synapse].setpost(PP)\n",
        "                break\n",
        "        else:  # If for finish the loop -> first appearance of this synapse\n",
        "            synapse.loc(seg_pointer.x, sec=seg_pointer.sec)\n",
        "            new_synapses_list.append(synapse)\n",
        "            synapses_per_seg[seg_pointer].append(synapse)\n",
        "\n",
        "    return new_synapses_list, subtree_ind_to_q\n",
        "\n",
        "def textify_seg_to_seg(segs):\n",
        "    '''convert segment dictionary to text'''\n",
        "    ret = {str(k): str(v) for k, v in segs.items()}\n",
        "    return ret\n",
        "   \n",
        "def subtree_reductor(original_cell,\n",
        "                     synapses_list,\n",
        "                     netcons_list,\n",
        "                     reduction_frequency,\n",
        "                     model_filename='model.hoc',\n",
        "                     total_segments_manual=-1,\n",
        "                     PP_params_dict=None,\n",
        "                     mapping_type='impedance',\n",
        "                     return_seg_to_seg=False\n",
        "                     ):\n",
        "\n",
        "    '''\n",
        "    Receives an instance of a cell with a loaded full morphology, a list of\n",
        "    synapse objects, a list of NetCon objects (the i'th netcon in the list\n",
        "    should correspond to the i'th synapse), the filename (string) of the model\n",
        "    template hoc file that the cell was instantiated from, the desired\n",
        "    reduction frequency as a float, optional parameter for the approximate\n",
        "    desired number of segments in the new model (if this parameter is empty,\n",
        "    the number of segments will be such that there is a segment for every 0.1\n",
        "    lambda), and an optional param for the point process to be compared before\n",
        "    deciding on whether to merge a synapse or not and reduces the cell (using\n",
        "    the given reduction_frequency). Creates a reduced instance using the model\n",
        "    template in the file whose filename is given as a parameter, and merges\n",
        "    synapses of the same type that get mapped to the same segment\n",
        "    (same \"reduced\" synapse object for them all, but different NetCon objects).\n",
        "    model_filename : model.hoc  will use a default template\n",
        "    total_segments_manual: sets the number of segments in the reduced model\n",
        "                           can be either -1, a float between 0 to 1, or an int\n",
        "                           if total_segments_manual = -1 will do automatic segmentation\n",
        "                           if total_segments_manual>1 will set the number of segments\n",
        "                           in the reduced model to total_segments_manual\n",
        "                           if 0>total_segments_manual>1 will automatically segment the model\n",
        "                           but if the automatic segmentation will produce a segment number that\n",
        "                           is lower than original_number_of_segments*total_segments_manual it\n",
        "                           will set the number of segments in the reduced model to:\n",
        "                           original_number_of_segments*total_segments_manual\n",
        "    return_seg_to_seg: if True the function will also return a textify version of the mapping\n",
        "                       between the original segments to the reduced segments \n",
        "    Returns the new reduced cell, a list of the new synapses, and the list of\n",
        "    the inputted netcons which now have connections with the new synapses.\n",
        "    Notes:\n",
        "    1) The original cell instance, synapses and Netcons given as arguments are altered\n",
        "    by the function and cannot be used outside of it in their original context.\n",
        "    2) Synapses are determined to be of the same type and mergeable if their reverse\n",
        "    potential, tau1 and tau2 values are identical.\n",
        "    3) Merged synapses are assigned a single new synapse object that represents them\n",
        "    all, but keep their original NetCon objects. Each such NetCon now connects the\n",
        "    original synapse's NetStim with\n",
        "    the reduced synapse.\n",
        "    '''\n",
        "    if PP_params_dict is None:\n",
        "        PP_params_dict = {}\n",
        "\n",
        "    h.init()\n",
        "\n",
        "    model_obj_name = load_model(model_filename)\n",
        "\n",
        "    # finds soma properties\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "\n",
        "    soma_cable = CableParams(length=soma.L, diam=soma.diam, space_const=None,\n",
        "                             cm=soma.cm, rm=1.0 / soma.g_pas, ra=soma.Ra, e_pas=soma.e_pas,\n",
        "                             electrotonic_length=None)\n",
        "\n",
        "    has_apical = len(list(original_cell.apical)) != 0\n",
        "\n",
        "    soma_ref = h.SectionRef(sec=soma)\n",
        "    axon_section, axon_is_parent, soma_axon_x = find_and_disconnect_axon(soma_ref)\n",
        "    roots_of_subtrees, num_of_subtrees = gather_subtrees(soma_ref)\n",
        "\n",
        "    sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index = \\\n",
        "        gather_cell_subtrees(roots_of_subtrees)\n",
        "\n",
        "    # preparing for reduction\n",
        "\n",
        "    # remove active conductances and get seg_to_mech dictionary\n",
        "    segment_to_mech_vals = create_segments_to_mech_vals(sections_to_delete)\n",
        "\n",
        "    # disconnects all the subtrees from the soma\n",
        "    subtrees_xs = []\n",
        "    for subtree_root in roots_of_subtrees:\n",
        "        subtrees_xs.append(subtree_root.parentseg().x)\n",
        "        h.disconnect(sec=subtree_root)\n",
        "\n",
        "    # reducing the subtrees\n",
        "    new_cable_properties = [reduce_subtree(roots_of_subtrees[i], reduction_frequency)\n",
        "                            for i in num_of_subtrees]\n",
        "\n",
        "    if total_segments_manual > 1:\n",
        "        new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "                                                           total_segments_manual)\n",
        "    else:\n",
        "        new_cables_nsegs = calculate_nsegs_from_lambda(new_cable_properties)\n",
        "        if total_segments_manual > 0:\n",
        "            original_cell_seg_n = (sum(i.nseg for i in list(original_cell.basal)) +\n",
        "                                   sum(i.nseg for i in list(original_cell.apical))\n",
        "                                   )\n",
        "            min_reduced_seg_n = int(round((total_segments_manual * original_cell_seg_n)))\n",
        "            if sum(new_cables_nsegs) < min_reduced_seg_n:\n",
        "                logger.debug(\"number of segments calculated using lambda is {}, \"\n",
        "                      \"the original cell had {} segments.  \"\n",
        "                      \"The min reduced segments is set to {}% of reduced cell segments\".format(\n",
        "                          sum(new_cables_nsegs),\n",
        "                          original_cell_seg_n,\n",
        "                          total_segments_manual * 100))\n",
        "                logger.debug(\"the reduced cell nseg is set to %s\" % min_reduced_seg_n)\n",
        "                new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "                                                                   min_reduced_seg_n)\n",
        "\n",
        "    cell, basals = create_reduced_cell(soma_cable,\n",
        "                                       has_apical,\n",
        "                                       original_cell,\n",
        "                                       model_obj_name,\n",
        "                                       new_cable_properties,\n",
        "                                       new_cables_nsegs,\n",
        "                                       subtrees_xs)\n",
        "\n",
        "    new_synapses_list, subtree_ind_to_q = merge_and_add_synapses(\n",
        "        num_of_subtrees,\n",
        "        new_cable_properties,\n",
        "        PP_params_dict,\n",
        "        synapses_list,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        netcons_list,\n",
        "        has_apical,\n",
        "        roots_of_subtrees,\n",
        "        original_cell,\n",
        "        basals,\n",
        "        cell,\n",
        "        reduction_frequency)\n",
        "\n",
        "    # create segment to segment mapping\n",
        "    original_seg_to_reduced_seg, reduced_seg_to_original_seg = create_seg_to_seg(\n",
        "        original_cell,\n",
        "        section_per_subtree_index,\n",
        "        roots_of_subtrees,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        new_cable_properties,\n",
        "        has_apical,\n",
        "        cell.apic,\n",
        "        basals,\n",
        "        subtree_ind_to_q,\n",
        "        mapping_type,\n",
        "        reduction_frequency)\n",
        "\n",
        "    # copy active mechanisms\n",
        "    copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        cell.apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type)\n",
        "    \n",
        "    if return_seg_to_seg:\n",
        "        original_seg_to_reduced_seg_text = textify_seg_to_seg(original_seg_to_reduced_seg)\n",
        "\n",
        "    # Connect axon back to the soma\n",
        "    if len(axon_section) > 0:\n",
        "        if axon_is_parent:\n",
        "            soma.connect(axon_section[0])\n",
        "        else:\n",
        "            axon_section[0].connect(soma, soma_axon_x)\n",
        "\n",
        "    # Now we delete the original model\n",
        "    for section in sections_to_delete:\n",
        "        with push_section(section):\n",
        "            h.delete_section()\n",
        "\n",
        "    cell.axon = axon_section\n",
        "    cell.dend = cell.hoc_model.dend\n",
        "\n",
        "    with push_section(cell.hoc_model.soma[0]):\n",
        "        h.delete_section()\n",
        "    if return_seg_to_seg:\n",
        "        return cell, new_synapses_list, netcons_list, original_seg_to_reduced_seg_text\n",
        "    else:\n",
        "        return cell, new_synapses_list, netcons_list\n",
        "\n",
        "\n",
        "class Neuron(object):\n",
        "    'Python neuron class for hoc models'\n",
        "    def __init__(self, model):\n",
        "        self.hoc_model = model\n",
        "        self.soma = None\n",
        "        self.dend = None\n",
        "        self.apic = None\n",
        "        self.axon = None\n",
        "\n",
        "\n",
        "def load_default_model():\n",
        "    h('''begintemplate model\n",
        "public init, biophys, geom_nseg, delete_axon, finish_creating_model_after_loading_morphology\n",
        "public soma, dend, apic, axon  // sections\n",
        "public all, somatic, apical, axonal, basal // section lists\n",
        "objref all, somatic, apical, axonal, basal, this\n",
        "proc init() {\n",
        "    all = new SectionList()\n",
        "    somatic = new SectionList()\n",
        "    basal = new SectionList()\n",
        "    apical = new SectionList()\n",
        "    axonal = new SectionList()\n",
        "    forall delete_section()\n",
        "    StepDist = 60 // human cells have no spines in their first 60 um\n",
        "                                // from soma - see Benavides-Piccione 2013\n",
        "    F_Spines = 1.9       //As calculated - see detailes in Eyal 2015\n",
        "    CM =0.45\t// uF/cm2\n",
        "    RM = 38907\n",
        "    RA = 203\n",
        "    E_PAS =  -86\n",
        "}\n",
        "create soma[1], dend[1], apic[1], axon[1]\n",
        "//external lambda_f\n",
        "proc geom_nseg() {\n",
        "    soma distance()\n",
        "    forsec all {\n",
        "        RA_calc = RA\n",
        "        RM_calc = RM*F_Spines\n",
        "        if (distance(1)>StepDist){\n",
        "            RA_calc = RA\n",
        "            RM_calc = RM*F_Spines\n",
        "        }\n",
        "        d = diam\n",
        "        lambda = sqrt(RM_calc/RA_calc*d/10000/4)*10000\n",
        "        nseg = int(L/lambda*10/2)*2+1\n",
        "    }\n",
        "}\n",
        "proc biophys() {\n",
        "    forsec all {\n",
        "        insert pas\n",
        "        cm =CM\n",
        "        g_pas=1/RM\n",
        "        Ra = RA\n",
        "        e_pas = E_PAS\n",
        "    }\n",
        "    soma distance()\n",
        "    forsec basal {\n",
        "        if (distance(0.5)>StepDist) {\n",
        "            L = L*F_Spines^(2/3)\n",
        "            diam = diam*(F_Spines^(1/3))\n",
        "        }\n",
        "    }\n",
        "    forsec apical {\n",
        "        if (distance(0.5)>StepDist) {\n",
        "            L = L*F_Spines^(2/3)\n",
        "            diam = diam*(F_Spines^(1/3))\n",
        "        }\n",
        "    }\n",
        "}\n",
        "proc delete_axon(){\n",
        "    forsec axonal{delete_section()}\n",
        "}\n",
        "proc complete_full_model_creation() {\n",
        "    geom_nseg()      \t\t             // calculates num of segments\n",
        "    delete_axon()\t\t                     // deletes the axon\n",
        "    biophys()\t\t\t             // increases cell dimensions to account for spines\n",
        "}\n",
        "endtemplate model''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmB_YMI9I56Y"
      },
      "source": [
        "tree_expander.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bj1XEnxqJBue",
        "outputId": "860ea46d-6870-4610-fa0c-38300f46d6ad"
      },
      "outputs": [],
      "source": [
        "#code for cable_expander.py\n",
        "'''\n",
        "Choose Branching point #Find apical branching segment in complex cell and choose the corresponding reduced segment using NR dictionary - have not automated this\n",
        "Complex: 'L5PCtemplate[0].apic[36](0.961538)' to reduced: model[0].apic[0](0.289004)\n",
        "The branching segment is at x=0.289004; section length: model[0].apic[0].L =2424.182421257107\n",
        "#Get desired trunk length from chosen branching point\n",
        "Trunk Length = x*L=0.289004*2424.182421257107=700\n",
        "'''\n",
        "#Get all other trunk cable properties by copying cylinder properties (this excludes mechanisms and synapses)\n",
        "\n",
        "#Adjust any trunk cable properties that are range variables (such as diameter) so that the range goes from rangevar(var(0),var(branching point)) instead of rangevar(var(0),var(1))\n",
        "#Get branch cable properties:\n",
        "\t\n",
        "#\tDiameter: Ralls D3/2 rule\n",
        "#Spatial Length: preserve maximum range of transfer impedance to soma or preserve surface area from replaced cylinder\n",
        "#Ra- same as trunk\n",
        "#\n",
        "#Collect mechanisms and synapses  from segments before (~trunk) and after (~branches) chosen branching point.\n",
        "#Delete apical cylinder\n",
        "#Build trunk, branches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6kAaRpoIr3I"
      },
      "outputs": [],
      "source": [
        "#testing area for functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atlls8ETHlg5"
      },
      "source": [
        "##Define The Cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejij0ArEHlBM"
      },
      "outputs": [],
      "source": [
        "#Run the code\n",
        "from __future__ import division\n",
        "from neuron import gui,h\n",
        "import numpy as np\n",
        "import neuron_reduce\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create a L5_PC model\n",
        "h.load_file('L5PCbiophys3.hoc')\n",
        "h.load_file(\"import3d.hoc\")\n",
        "h.load_file('L5PCtemplate.hoc')\n",
        "complex_cell = h.L5PCtemplate('cell1.asc')\n",
        "h.celsius = 37\n",
        "h.v_init = complex_cell.soma[0].e_pas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmh5X-fHnfg"
      },
      "source": [
        "Add synapses to the cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKb-1N49aCkR"
      },
      "outputs": [],
      "source": [
        "#Add synapses to the model\n",
        "synapses_list, netstims_list, netcons_list, randoms_list = [], [], [] ,[]\n",
        "\n",
        "all_segments = [i for j in map(list,list(complex_cell.apical)) for i in j] + [i for j in map(list,list(complex_cell.basal)) for i in j]\n",
        "len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in all_segments])\n",
        "rnd = np.random.RandomState(10)\n",
        "for i in range(10000):\n",
        "    seg_for_synapse = rnd.choice(all_segments,   p=len_per_segment/sum(len_per_segment)) #choose a random segment with probability based on the length of segment\n",
        "    synapses_list.append(h.Exp2Syn(seg_for_synapse))\n",
        "    if rnd.uniform()<0.85: # 85% synapses are excitatory\n",
        "        e_syn, tau1, tau2, spike_interval, syn_weight = 0, 0.3, 1.8,  1000/2.5, 0.0016\n",
        "    else: #inhibitory case\n",
        "        e_syn, tau1, tau2, spike_interval, syn_weight = -86, 1,   8,   1000/15.0, 0.0008\n",
        "    #set synaptic varibales\n",
        "    synapses_list[i].e, synapses_list[i].tau1, synapses_list[i].tau2 = e_syn, tau1, tau2\n",
        "    #set netstim variables\n",
        "    netstims_list.append(h.NetStim())\n",
        "    netstims_list[i].interval, netstims_list[i].number, netstims_list[i].start, netstims_list[i].noise = spike_interval, 9e9, 100, 1\n",
        "    #set random\n",
        "    randoms_list.append(h.Random())\n",
        "    randoms_list[i].Random123(i)\n",
        "    randoms_list[i].negexp(1)\n",
        "    netstims_list[i].noiseFromRandom(randoms_list[i])       \n",
        "    #set netcon varibales \n",
        "    netcons_list.append(h.NetCon(netstims_list[i], synapses_list[i] ))\n",
        "    netcons_list[i].delay, netcons_list[i].weight[0] = 0, syn_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL9epdD5cpuK"
      },
      "source": [
        "Simulate the complex cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mz9SNTSHu17",
        "outputId": "abb0e722-721c-415d-b1e4-99d5d84d6f12"
      },
      "outputs": [],
      "source": [
        "soma_v = h.Vector()\n",
        "soma_v.record(complex_cell.soma[0](0.5)._ref_v)\n",
        "\n",
        "time_v = h.Vector()\n",
        "time_v.record(h._ref_t)\n",
        "\n",
        "h.tstop = 1000\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('complex cell simulation time {:.4f}'.format(time.time()-st))\n",
        "complex_cell_v = list(soma_v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "CL0mlEexH3f2",
        "outputId": "74bc6657-d9dd-4f48-cf80-5bd2e8f9dedb"
      },
      "outputs": [],
      "source": [
        "#apply Neuron_Reduce to simplify the cell\n",
        "reduced_cell, synapses_list, netcons_list, txt = subtree_reductor(complex_cell, synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)\n",
        "for r in randoms_list:r.seq(1) #reset random\n",
        "\n",
        "\n",
        "#Running the simulation again but now on the reduced cell\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('reduced cell simulation time {:.4f}'.format(time.time()-st))\n",
        "reduced_celll_v = list(soma_v)\n",
        "\n",
        "#plotting the results\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(time_v, complex_cell_v, label='complex cell')\n",
        "plt.plot(time_v, reduced_celll_v,  label='reduced cell')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE7g7hCZ4dg0",
        "outputId": "bcd9f69c-7e5d-424a-8f9a-f680d9f8af72"
      },
      "outputs": [],
      "source": [
        "# print(txt) #shows how the original segments were mapped to the reduced segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OGD7GLm8CQ9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model[0].apic[0](0.289004)\n"
          ]
        }
      ],
      "source": [
        "# txt.get('L5PCtemplate[0].apic[0](0.166667)')\n",
        "branching_seg=txt.get('L5PCtemplate[0].apic[36](0.961538)') #shows the reduced segment that the complex nexus branching segment mapped to\n",
        "# branching_seg=txt.get('L5PCtemplate[0].apic[36](0.5)')\n",
        "print(branching_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(branching_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8cQzsrQXlFw",
        "outputId": "7e074adf-0f73-4656-dd4e-2705bd0f55e1"
      },
      "outputs": [],
      "source": [
        "branching_seg = branching_seg.replace(\"[0]\", \"\",1)\n",
        "print(branching_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkArax9aYBhc"
      },
      "outputs": [],
      "source": [
        "branching_seg=\"reduced_cell.hoc_\"+branching_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQEEHj7JYWY_",
        "outputId": "2e964854-b91d-4dbd-d65b-126ac626e6f6"
      },
      "outputs": [],
      "source": [
        "print(branching_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpHYc36iWlFo",
        "outputId": "47e2ff9f-11fa-417c-8bfc-38aa34cb8c6d"
      },
      "outputs": [],
      "source": [
        "exec(\"print(dir(\"+branching_seg+\"))\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYPHXEdlW4eK"
      },
      "outputs": [],
      "source": [
        "sections_to_expand=[reduced_cell.hoc_model.apic[0]] #list of sections to expand\n",
        "branching_x=0.289004"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKgOd814xMrm",
        "outputId": "44d87f48-3695-47ab-c033-c7d9eaee20e3"
      },
      "outputs": [],
      "source": [
        "print(sections_to_expand[0](0.000000000000000001).pas.g)\n",
        "print(sections_to_expand[0](0.9999999999999999).pas.g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YkWlnJ4BtnG"
      },
      "outputs": [],
      "source": [
        "#change cable params\n",
        "CableParams = collections.namedtuple('CableParams',\n",
        "                                     'length, diam, space_const,'\n",
        "                                     'cm, rm, ra, e_pas, electrotonic_length, type, furcation_x'\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Maa2a93eDehN"
      },
      "outputs": [],
      "source": [
        "def apply_params_to_section(name, type_of_sectionlist, instance_as_str, section, cable_params, nseg):\n",
        "    section.L = cable_params.length\n",
        "    section.diam = cable_params.diam\n",
        "    section.nseg = nseg\n",
        "\n",
        "    append_to_section_lists(name, type_of_sectionlist, instance_as_str)\n",
        "\n",
        "    section.insert('pas')\n",
        "    section.cm = cable_params.cm\n",
        "    section.g_pas = 1.0 / cable_params.rm\n",
        "    section.Ra = cable_params.ra\n",
        "    section.e_pas = cable_params.e_pas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6-CXDVOQWv8"
      },
      "outputs": [],
      "source": [
        "#changing reduce_subtree(subtree_root_section) into expand_cylinder(reduced_section)\n",
        "def expand_cable(section_to_expand, frequency, furcation_x, nbranch):\n",
        "    '''expand a cylinder (cable) from the reduced_cell into one trunk and nbranch identical branch sections.\n",
        "    The expansion is done by finding the lengths and diameters of the trunk and branch.\n",
        "    Trunk length is chosen using the furcation point.\n",
        "    Trunk diameter is the same as the cable.\n",
        "    Branch Diameter is chosen using the 3/2 power rule.\n",
        "    Branch length is chosen so that electrotonic length of the dendritic tree is the same as the cable's electrotonic length.\n",
        "    '''\n",
        "\n",
        "    section_to_expand_ref = h.SectionRef(sec=section_to_expand)\n",
        "    sec_type=section_to_expand.name().split(\".\")[1][:4] #get section type\n",
        "    cm, rm, ra, e_pas, q = _get_subtree_biophysical_properties(section_to_expand, frequency)\n",
        "\n",
        "    # finds the subtree's input impedance (at the somatic-proximal end of the\n",
        "    # subtree root section) and the lowest transfer impedance in the subtree in\n",
        "    # relation to the somatic-proximal end (see more in Readme on NeuroReduce)\n",
        "    imp_obj, root_input_impedance = measure_input_impedance_of_subtree(section_to_expand, frequency)\n",
        "\n",
        "    # in Ohms (a complex number)\n",
        "    curr_lowest_subtree_imp = find_lowest_subtree_impedance(section_to_expand_ref, imp_obj)\n",
        "\n",
        "    # expanding the single cylinder into one trunk and multiple tufts\n",
        "    trunk_diam = section_to_expand.diam\n",
        "    trunk_diam_in_cm=trunk_diam/10000\n",
        "    trunk_Ri = section_to_expand.Ra\n",
        "    trunk_Rm = 1/section_to_expand(0.5).pas.g\n",
        "    trunk_L = section_to_expand.L*furcation_x #since trunk has same Ri,Rm,d electrotonically the same as cable\n",
        "\n",
        "\n",
        "    branch_diam=(trunk_diam**(3/2)/nbranch)**(2/3) # d(3/2) power rule. solving trunk_d^(3/2)=sum(branch_diam^3/2) for branch diam\n",
        "    branch_diam_in_cm = branch_diam/10000\n",
        "    branch_Ri=trunk_Ri\n",
        "    branch_Rm=trunk_Rm\n",
        "    \n",
        "    cable_space_const_in_cm = find_space_const_in_cm(section_to_expand(0.5).diam/10000,\n",
        "                                                    rm,\n",
        "                                                    ra)\n",
        "    cable_space_const_in_um=cable_space_const_in_cm*10000\n",
        "    # solving cable_elec_L = dend_elec_L = trunk_elec_L + branch_elec_L for branch electrotonic length for one order of branching\n",
        "    cable_elec_L = section_to_expand.L/cable_space_const_in_um\n",
        "    trunk_elec_L = trunk_L*cable_elec_L/section_to_expand_ref.sec.L\n",
        "    branch_elec_L = cable_elec_L-trunk_elec_L\n",
        "    # solving elec_L=Length/sqrt((Rm/Ri)*(d/4)) for Length\n",
        "    # branch_L = branch_elec_L*np.sqrt((branch_Rm/branch_Ri)*(branch_diam_in_cm/4))\n",
        "    # branch_L=branch_L*10000\n",
        "\n",
        "\n",
        "    # calculating the space constant, in order to find the cylinder's length:\n",
        "    # space_const = sqrt(rm/(ri+r0))\n",
        "    trunk_space_const_in_cm = find_space_const_in_cm(trunk_diam_in_cm,\n",
        "                                                    rm,\n",
        "                                                    ra)\n",
        "    trunk_space_const_in_micron = 10000 * trunk_space_const_in_cm\n",
        "\n",
        "    branch_space_const_in_cm = find_space_const_in_cm(branch_diam_in_cm,\n",
        "                                                    rm,\n",
        "                                                    ra)\n",
        "    branch_space_const_in_micron = 10000 * branch_space_const_in_cm\n",
        "    \n",
        "    branch_L=branch_elec_L*branch_space_const_in_micron\n",
        "    \n",
        "    print('trunk_diam:',trunk_diam,'|trunk_length:',trunk_L,'|branch_diam:',branch_diam,'|branch_length:',branch_L)\n",
        "    # len(CableParams)\n",
        "\n",
        "    return CableParams(length=trunk_L,\n",
        "                       diam=trunk_diam,\n",
        "                       space_const=trunk_space_const_in_micron,\n",
        "                       cm=cm,\n",
        "                       rm=rm,\n",
        "                       ra=ra,\n",
        "                       e_pas=e_pas,\n",
        "                       electrotonic_length=trunk_elec_L,\n",
        "                       type=sec_type,\n",
        "                       furcation_x=furcation_x),CableParams(length=branch_L,\n",
        "                       diam=branch_diam,\n",
        "                       space_const=branch_space_const_in_micron,\n",
        "                       cm=cm,\n",
        "                       rm=rm,\n",
        "                       ra=ra,\n",
        "                       e_pas=e_pas,\n",
        "                       electrotonic_length=branch_elec_L,\n",
        "                       type=sec_type,\n",
        "                       furcation_x=furcation_x),sec_type\n",
        "    \n",
        "def calc_elec_length(sec):\n",
        "  '''\n",
        "  calculates the entire electrotonic length of a uniform section\n",
        "  elec_L=Length/sqrt((Rm/Ri)*(d/4)) \n",
        "  Where Rm is membrane resistance time unit area (in ohms*(cm)^2) \n",
        "  and Ri is specific intracellular resisitivity (ohms*cm).\n",
        "  '''\n",
        "  d=sec(0.5).diam*10000 #convert microns (10**-6) to cm (10**-2)\n",
        "  elec_L=sec.L/np.sqrt((sec(0.5).pas.g/sec.Ra)*(d/4))\n",
        "  return elec_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kynTBJT03vHy"
      },
      "outputs": [],
      "source": [
        "#changing create_reduced_cell into create_dendritic_cell\n",
        "def create_dendritic_cell(soma_cable,\n",
        "                        has_apical,\n",
        "                        original_cell,\n",
        "                        model_obj_name,\n",
        "                        trunk_cable_properties, branch_cable_properties, nbranches,sections_to_expand,sections_to_keep, #new_cable_properties,  #lists for each expansion\n",
        "                        trunk_nsegs, branch_nsegs, #new_cables_nsegs,\n",
        "                        subtrees_xs):\n",
        "    h(\"objref reduced_dendritic_cell\")\n",
        "    h(\"reduced_dendritic_cell = new \" + model_obj_name + \"()\")\n",
        "\n",
        "    create_sections_in_hoc(\"soma\", 1, \"reduced_dendritic_cell\")\n",
        "\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "    append_to_section_lists(\"soma[0]\", \"somatic\", \"reduced_dendritic_cell\")\n",
        "    sec_type_list=[]\n",
        "    trunk_sec_type_list = []\n",
        "    kept_sec_type_list = []\n",
        "    apicals=[]\n",
        "    basals=[]\n",
        "    all_sections=[]\n",
        "    trunks=[] # list of trunk sections\n",
        "    branches=[] # list of branch sections for each trunk [[first trunk's branches][2nd trunk's..]]\n",
        "    #get original_cell type list lengths\n",
        "    # \n",
        "    # get \n",
        "    for i,sec in enumerate(sections_to_expand):\n",
        "      sec_type=sec.name().split(\".\")[1][:4] #get section type\n",
        "      # sec_index_for_type=sec.name().split(\"[\")[2].split(\"]\")[0] # get the index for the section within the section type list\n",
        "      sec_type_list.append(sec_type) #append trunk sec_type \n",
        "      trunk_sec_type_list.append(sec_type) #append trunk sec_type to its own list\n",
        "      #include branches\n",
        "      for nbranch in nbranches:\n",
        "        for i in range(nbranch):\n",
        "          sec_type_list.append(sec_type) # append branches sec_type (same as trunk)\n",
        "\n",
        "\n",
        "    for i,sec in enumerate(sections_to_keep):\n",
        "      sec_type=sec.name().split(\".\")[1][:4] #get section type\n",
        "      # sec_index_for_type=sec.name().split(\"[\")[2].split(\"]\")[0] # get the index for the section within the section type list\n",
        "      sec_type_list.append(sec_type)\n",
        "      kept_sec_type_list.append(sec_type)\n",
        "\n",
        "\n",
        "    #create section lists with the total number of sections for each section type\n",
        "    unique_sec_types=[]\n",
        "    for sec_type in sec_type_list:\n",
        "      if sec_type not in unique_sec_types:\n",
        "        unique_sec_types.append(sec_type)\n",
        "    print('sec_type_list:',sec_type_list)\n",
        "    print('unique_sec_types:',unique_sec_types)\n",
        "    for unique_sec_type in unique_sec_types:\n",
        "      num_sec_type_for_this_unique_sec_type=sec_type_list.count(unique_sec_type)\n",
        "      print(unique_sec_type)\n",
        "      print(num_sec_type_for_this_unique_sec_type)\n",
        "      create_sections_in_hoc(unique_sec_type,num_sec_type_for_this_unique_sec_type,\"reduced_dendritic_cell\")\n",
        "      print(len(h.reduced_dendritic_cell.apic))\n",
        "      if unique_sec_type=='apic':\n",
        "        apicals = [h.reduced_dendritic_cell.apic[i] for i in range(num_sec_type_for_this_unique_sec_type)]\n",
        "      elif unique_sec_type == 'dend':\n",
        "        basals = [h.reduced_dendritic_cell.dend[i] for i in range(num_sec_type_for_this_unique_sec_type)]\n",
        "      elif unique_sec_type == 'axon':\n",
        "        axonal = [h.reduced_dendritic_cell.axon[i] for i in range(num_sec_type_for_this_unique_sec_type)]\n",
        "      else:\n",
        "        print('error: sec_type', sec_type,' is not \"apic\" or \"dend\"')\n",
        "\n",
        "        # for i in range(sec_type_list):\n",
        "        #   new_section=h.reduced_cell.getattr(sec_type)[i]\n",
        "\n",
        "    #assemble tree sections\n",
        "    number_of_sections_in_apical_list=0 # count as we add sections since cannot do len(h.reduced_cell.apical)\n",
        "    number_of_sections_in_basal_list=0\n",
        "    number_of_sections_in_axonal_list=0\n",
        "    trunk_sec_type_list_indices=[]\n",
        "    for i in range(len(trunk_cable_properties)):\n",
        "        trunk_cable_params = trunk_cable_properties[i]\n",
        "        branch_cable_params = branch_cable_properties[i]\n",
        "        trunk_nseg = trunk_nsegs[i]\n",
        "        branch_nseg = branch_nsegs[i]\n",
        "        nbranch=nbranches[i]\n",
        "        trunk_sec_type=trunk_sec_type_list[i]\n",
        "\n",
        "        if trunk_sec_type=='dend': # basal \n",
        "          #trunk\n",
        "          trunk_index=number_of_sections_in_basal_list # trunk index of basal list\n",
        "          trunk_cable_params.sec_index_for_type=trunk_index\n",
        "          print('test: trunk_cable_params.sec_index_for_type:',trunk_cable_params.sec_index_for_type) #check is this works\n",
        "          apply_params_to_section(\"dend\"+\"[\" + str(trunk_index) + \"]\", \"basal\", \"reduced_cell\",  #apply params to trunk\n",
        "                                basals[trunk_index], trunk_cable_params, trunk_nseg)\n",
        "          basals[trunk_index].connect(soma, subtrees_xs[i], 0) #connect trunk to soma where it was previously connected\n",
        "          trunk_sec_type_list_indices.append(trunk_index) #get list of trunk indices for trunk's respective sec_type_list (apic or dend)\n",
        "          trunks.append(basals[trunk_index])\n",
        "          number_of_basal_sections_in_basal_list+=1\n",
        "          #branches\n",
        "          branches_for_trunk = [] # list of branches for this trunk\n",
        "          for j in range(nbranch): #apply branch parameters to next nbranch sections\n",
        "                    branch_index=number_of_sections_in_apical_list\n",
        "                    apply_params_to_section(\"dend\"+\"[\" + str(branch_index) + \"]\", \"basal\", \"reduced_cell\",  #apply params to branch\n",
        "                                basals[branch_index], branch_cable_params, branch_nseg)\n",
        "                    basals[branch_index].connect(basals[trunk_index], 1, 0) # connect branch to distal end of trunk\n",
        "                    number_of_sections_in_basal_list+=1\n",
        "                    branches_for_trunk.append(basals[branch_index])\n",
        "          branches.append(branches_for_trunk)\n",
        "\n",
        "        elif trunk_sec_type=='apic': # apical\n",
        "          #trunk\n",
        "          trunk_index=number_of_sections_in_apical_list\n",
        "          apply_params_to_section(\"apic\"+\"[\" + str(trunk_index) + \"]\", \"apical\", \"reduced_cell\",  #apply params to trunk\n",
        "                                apicals[trunk_index], trunk_cable_params, trunk_nseg)\n",
        "          apicals[trunk_index].connect(soma, subtrees_xs[i], 0) #connect trunk to soma where it was previously connected\n",
        "          trunk_sec_type_list_indices.append(trunk_index) #get list of trunk indices for trunk's respective sec_type_list (apic or dend)\n",
        "          number_of_sections_in_apical_list+=1\n",
        "          #branches\n",
        "          branches_for_trunk = []\n",
        "          for j in range(nbranch): #apply branch parameters to next nbranch sections\n",
        "                    branch_index=number_of_sections_in_apical_list\n",
        "                    apply_params_to_section(\"apic\"+\"[\" + str(branch_index) + \"]\", \"apical\", \"reduced_dendritic_cell\", #apply params to branch\n",
        "                                apicals[branch_index], branch_cable_params, branch_nseg)\n",
        "                    apicals[branch_index].connect(apicals[trunk_index], 1, 0) # connect branch to distal end of trunk\n",
        "                    trunks.append(apicals[trunk_index])\n",
        "                    number_of_sections_in_apical_list+=1\n",
        "                    branches_for_trunk.append(apicals[branch_index])\n",
        "          branches.append(branches_for_trunk)\n",
        "\n",
        "        else:\n",
        "          raise(trunk_sec_type,'is not \"apic\" or \"dend\"')\n",
        "    for i in range(len(sections_to_keep)): #add kept sections to the section lists\n",
        "      if kept_sec_type_list[i]=='apic':\n",
        "        sec_index=number_of_sections_in_apical_list\n",
        "        append_to_section_lists(\"apic\"+\"[\" + str(sec_index) + \"]\", \"apical\", \"reduced_dendritic_cell\")\n",
        "        number_of_sections_in_apical_list+=1\n",
        "      elif kept_sec_type_list[i]=='dend':\n",
        "        sec_index=number_of_sections_in_basal_list\n",
        "        append_to_section_lists(\"dend\"+\"[\" + str(sec_index) + \"]\", \"basal\", \"reduced_dendritic_cell\")\n",
        "        number_of_sections_in_basal_list+=1\n",
        "      elif kept_sec_type_list[i]=='axon':\n",
        "        sec_index=number_of_sections_in_axonal_list\n",
        "        append_to_section_lists(\"axon\"+\"[\" + str(sec_index) + \"]\", \"axonal\", \"reduced_dendritic_cell\")\n",
        "        number_of_sections_in_axonal_list+=1\n",
        "      else:\n",
        "        raise(kept_sec_type_list[i],'is not \"apic\" , \"dend\" , \"axon\"')\n",
        "\n",
        "    # create cell python template\n",
        "    cell = Neuron(h.reduced_cell)\n",
        "    cell.soma = original_cell.soma\n",
        "    # cell.apic = apic\n",
        "\n",
        "    return cell, basals, apicals, trunk_sec_type_list_indices, trunks, branches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M_NmlhiKF54"
      },
      "outputs": [],
      "source": [
        "def find_and_disconnect_sections_to_keep(soma_ref,sections_to_expand):\n",
        "    '''Searching for sections to keep, they can be a child of the soma or a parent of the soma.'''\n",
        "    sections_to_keep, is_section_to_keep_soma_parent, soma_sections_to_keep_x  = [], [], []\n",
        "    for sec in soma_ref.child:\n",
        "        # name = sec.hname().lower()\n",
        "        if sec not in sections_to_expand:\n",
        "            sections_to_keep.append(sec)\n",
        "            is_section_to_keep_soma_parent.append(False)\n",
        "            # disconnect section\n",
        "            soma_sections_to_keep_x.append(sec.parentseg().x)\n",
        "            sec.push()\n",
        "            h.disconnect()\n",
        "            h.define_shape()\n",
        "\n",
        "    if soma_ref.has_parent():\n",
        "            sections_to_keep.append(soma_ref.parent())\n",
        "            is_section_to_keep_soma_parent.append(True)\n",
        "            soma_sections_to_keep_x.append(None)\n",
        "            soma_ref.push()\n",
        "            h.disconnect()\n",
        "    # else:\n",
        "    #     raise Exception('Soma has a parent which is not an axon')\n",
        "\n",
        "    return sections_to_keep, is_section_to_keep_soma_parent, soma_sections_to_keep_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfzivIepONfw"
      },
      "outputs": [],
      "source": [
        "def gather_cell_subtrees(roots_of_subtrees):\n",
        "    # dict that maps section indexes to the subtree index they are in: keys are\n",
        "    # string tuples: (\"apic\"/\"basal\", orig_section_index) , values are ints:\n",
        "    # subtree_instance_index\n",
        "    sections_to_delete = []\n",
        "    section_per_subtree_index = {}\n",
        "    mapping_sections_to_subtree_index = {}\n",
        "    for i, soma_child in enumerate(roots_of_subtrees):\n",
        "        # inserts each section in this subtree into the above dict, which maps\n",
        "        # it to the subtree index\n",
        "        if 'apic' in soma_child.hname():\n",
        "            assert i == 0, ('The apical is not the first child of the soma! '\n",
        "                            'a code refactoring is needed in order to accept it')\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"apic\",\n",
        "                                                     i)\n",
        "        elif 'dend' in soma_child.hname() or 'basal' in soma_child.hname():\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"basal\",\n",
        "                                                     i)\n",
        "\n",
        "    return sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9aYSNeCt8r_"
      },
      "outputs": [],
      "source": [
        "def expand_synapse(cell_instance,\n",
        "                   synapse_location,\n",
        "                   on_basal,\n",
        "                   imp_obj,\n",
        "                   root_input_impedance,\n",
        "                   trunk_properties,branch_properties,furcation_x,\n",
        "                   q_subtree):\n",
        "    '''\n",
        "    Receives an instance of a cell, the location (section + relative\n",
        "    location(x)) of a synapse to be reduced, a boolean on_basal that is True if\n",
        "    the synapse is on a basal subtree, the number of segments in the reduced\n",
        "    cable that this synapse is in, an Impedance calculating Hoc object, the\n",
        "    input impedance at the root of this subtree, and the electrotonic length of\n",
        "    the reduced cable that represents the current subtree\n",
        "    (as a real and as a complex number) -\n",
        "    and maps the given synapse to its new location on the reduced cable\n",
        "    according to the NeuroReduce algorithm.  Returns the new \"post-merging\"\n",
        "    relative location of the synapse on the reduced cable (x, 0<=x<=1), that\n",
        "    represents the middle of the segment that this synapse is located at in the\n",
        "    new reduced cable.\n",
        "    '''\n",
        "    # measures the original transfer impedance from the synapse to the\n",
        "    # somatic-proximal end in the subtree root section\n",
        "    if not on_basal:  # apical subtree\n",
        "        section = cell_instance.apic[synapse_location.section_num]\n",
        "    else:             # basal subtree\n",
        "        section = cell_instance.dend[synapse_location.section_num]\n",
        "\n",
        "    with push_section(section):\n",
        "        orig_transfer_imp = imp_obj.transfer(synapse_location.x) * 1000000  # ohms\n",
        "        orig_transfer_phase = imp_obj.transfer_phase(synapse_location.x)\n",
        "        # creates a complex Impedance value with the given polar coordinates\n",
        "        orig_synapse_transfer_impedance = cmath.rect(orig_transfer_imp, orig_transfer_phase)\n",
        "\n",
        "    # synapse location could be calculated using:\n",
        "    # X = L - (1/q) * arcosh( (Zx,0(f) / ZtreeIn(f)) * cosh(q*L) ),\n",
        "    # derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    # but we chose to find the X that will give the correct modulus. See comment about L values\n",
        "\n",
        "    elec_L_dend=trunk_properties.electrotonic_length+branch_properties.electrotonic_length\n",
        "\n",
        "\n",
        "    synapse_new_electrotonic_location = find_best_real_X(root_input_impedance,\n",
        "                                                         orig_synapse_transfer_impedance,\n",
        "                                                         q_subtree,\n",
        "                                                         new_cable_electrotonic_length=elec_L_dend)\n",
        "                                                         \n",
        "    #relative location along entire dendrite                                                     \n",
        "    new_relative_loc_in_section = (float(synapse_new_electrotonic_location) /\n",
        "                                   elec_L_dend)\n",
        "    #determine x loc is  trunk or branch\n",
        "    if new_relative_loc_in_section<furcation_x: #trunk\n",
        "      on_trunk=True\n",
        "      new_relative_loc_in_section = new_relative_loc_in_section/furcation_x #adjust for section x loc\n",
        "    else: #branch case\n",
        "      on_trunk=False\n",
        "      branch_elec_L_for_synapse = synapse_new_electrotonic_location-trunk_properties.electrotonic_length\n",
        "      # solve branch_elec_L_for_synapse = branch_syn_L/branch_space_const for branch_syn_L (the length up the branch to the synapses electrotonic length)\n",
        "      branch_L_for_synapse = branch_elec_L_for_synapse*branch_properties.space_constant\n",
        "      # find proportionate length for x doing L_syn/L_branch\n",
        "      new_relative_loc_in_section = branch_L_for_synapse/branch_properties.length\n",
        "\n",
        "    if new_relative_loc_in_section > 1:  # PATCH\n",
        "        new_relative_loc_in_section = 0.999999\n",
        "\n",
        "    return new_relative_loc_in_section, on_trunk\n",
        "\n",
        "def find_branch_synapse_X(cell_instance,\n",
        "                   synapse_location,\n",
        "                   on_basal,\n",
        "                   imp_obj,\n",
        "                   root_input_impedance,\n",
        "                   new_cable_electrotonic_length,\n",
        "                   q_subtree,\n",
        "                   trunk_properties, branch_properties):\n",
        "    '''\n",
        "    Receives an instance of a cell, the location (section + relative\n",
        "    location(x)) of a synapse to be reduced, a boolean on_basal that is True if\n",
        "    the synapse is on a basal subtree, the number of segments in the reduced\n",
        "    cable that this synapse is in, an Impedance calculating Hoc object, the\n",
        "    input impedance at the root of this subtree, and the electrotonic length of\n",
        "    the reduced cable that represents the current subtree\n",
        "    (as a real and as a complex number) -\n",
        "    and maps the given synapse to its new location on the reduced cable\n",
        "    according to the NeuroReduce algorithm.  Returns the new \"post-merging\"-\n",
        "    relative location of the synapse on the reduced cable (x, 0<=x<=1), that\n",
        "    represents the middle of the segment that this synapse is located at in the\n",
        "    new reduced cable.\n",
        "    '''\n",
        "    # measures the original transfer impedance from the synapse to the\n",
        "    # somatic-proximal end in the subtree root section\n",
        "    if not on_basal:  # apical subtree\n",
        "        section = cell_instance.apic[synapse_location.section_num]\n",
        "    else:             # basal subtree\n",
        "        section = cell_instance.dend[synapse_location.section_num]\n",
        "\n",
        "    with push_section(section):\n",
        "        orig_transfer_imp = imp_obj.transfer(synapse_location.x) * 1000000  # ohms\n",
        "        orig_transfer_phase = imp_obj.transfer_phase(synapse_location.x)\n",
        "        # creates a complex Impedance value with the given polar coordinates\n",
        "        orig_synapse_transfer_impedance = cmath.rect(orig_transfer_imp, orig_transfer_phase)\n",
        "\n",
        "    # synapse location could be calculated using:\n",
        "    # X = L - (1/q) * arcosh( (Zx,0(f) / ZtreeIn(f)) * cosh(q*L) ),\n",
        "    # derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    # but we chose to find the X that will give the correct modulus. See comment about L values\n",
        "\n",
        "    synapse_new_electrotonic_location = find_best_real_X(root_input_impedance,\n",
        "                                                         orig_synapse_transfer_impedance,\n",
        "                                                         q_subtree,\n",
        "                                                         new_cable_electrotonic_length)\n",
        "    #solve syn_elec_L=trunk_elec_L+branch_elec_L for branch_elec_L\n",
        "    branch_elec_L_for_synapse = synapse_new_electrotonic_location-trunk_properties.electrotonic_length\n",
        "    # solve branch_elec_L_for_synapse = branch_syn_L/branch_space_const for branch_syn_L (the length up the branch to the synapses electrotonic length)\n",
        "    branch_L_for_synapse = branch_elec_L_for_synapse*branch_properties.space_constant\n",
        "    # find proportionate length for x doing L_syn/L_branch\n",
        "    new_relative_loc_in_section = branch_L_for_synapse/branch_properties.length\n",
        "\n",
        "    if new_relative_loc_in_section > 1:  # PATCH\n",
        "        new_relative_loc_in_section = 0.999999\n",
        "\n",
        "    return new_relative_loc_in_section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHPfoyAiSD5d"
      },
      "outputs": [],
      "source": [
        "def adjust_new_tree_synapses(num_sections_to_expand,\n",
        "                           trunk_properties, branch_properties, nbranches, furcations_x, all_trunk_sec_type, trunk_sec_type_list_indices, #list of indices for dend[], apic[] of trunk sections\n",
        "                           PP_params_dict,\n",
        "                           synapses_list,\n",
        "                           mapping_sections_to_subtree_index,\n",
        "                           netcons_list,\n",
        "                           has_apical,\n",
        "                           sections_to_expand,\n",
        "                           original_cell,\n",
        "                           basals, apicals,\n",
        "                           cell,\n",
        "                           reduction_frequency):\n",
        "    # dividing the original synapses into baskets, so that all synapses that are\n",
        "    # on the same subtree will be together in the same basket\n",
        "\n",
        "    # a list of baskets of synapses, each basket in the list will hold the\n",
        "    # synapses of the subtree of the corresponding basket index\n",
        "    baskets = [[] for _ in sections_to_expand]\n",
        "    soma_synapses_syn_to_netcon = {}\n",
        "\n",
        "    new_synapses_list, subtree_ind_to_q = [], {}\n",
        "\n",
        "    for syn_index, synapse in enumerate(synapses_list):\n",
        "      # if synapse.sec in sections_to_expand:\n",
        "        synapse_location = find_synapse_loc(synapse, mapping_sections_to_subtree_index)\n",
        "\n",
        "        # for a somatic synapse\n",
        "        # TODO: 'axon' is never returned by find_synapse_loc...\n",
        "        if synapse_location.subtree_index in (SOMA_LABEL, 'axon'):\n",
        "            soma_synapses_syn_to_netcon[synapse] = netcons_list[syn_index]\n",
        "        else:\n",
        "            baskets[synapse_location.subtree_index].append((synapse, synapse_location, syn_index))\n",
        "      # else: #leave synapses not on new trees synapses alone\n",
        "      #   new_synapses_list.append(synapse)\n",
        "\n",
        "    # mapping (non-somatic) synapses to their new location on the reduced model\n",
        "    # (the new location is the exact location of the middle of the segment they\n",
        "    # were mapped to, in order to enable merging)\n",
        "    for section_to_expand_index in len(sections_to_expand):\n",
        "        imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "            sections_to_expand[section_to_expand_index], reduction_frequency)\n",
        "        subtree_ind_to_q[section_to_expand_index] = calculate_subtree_q(\n",
        "            sections_to_expand[section_to_expand_index], reduction_frequency)\n",
        "        \n",
        "        trunk_index = trunk_sec_type_list_indices[section_to_expand_index]\n",
        "        x_furcation = furcations_x[section_to_expand_index]\n",
        "        # iterates over the synapses in the curr basket\n",
        "        for synapse, synapse_location, syn_index in baskets[section_to_expand_index]:\n",
        "            # get trunk synapses\n",
        "            if synapse.x < x_furcation: #synapse proximal to furcation point is on trunk\n",
        "              #locate this trunk section\n",
        "              if all_trunk_sec_type[section_to_expand_index]=='dend':\n",
        "                section_for_synapse = basals[trunk_index] #get the trunk section\n",
        "              elif all_trunk_sec_type[section_to_expand_index]=='apic':\n",
        "                section_for_synapse = apicals[trunk_index]\n",
        "              else:\n",
        "                raise(all_trunk_sec_type[section_to_expand_index],' is not \"apic\" or \"dend\"')\n",
        "              #adjust x location since trunk is fraction of cable length\n",
        "              x = synapse.x/x_furcation\n",
        "            else: #synapse is distal to furcation meaning on branch\n",
        "              nbranch=nbranches[section_to_expand_index] # number of branches on this tree\n",
        "              branch_index=trunk_index+int(np.random.uniform(1,nbranch+1)) #select random branch on this tree to move synapse to\n",
        "              if all_trunk_sec_type[section_to_expand_index]=='dend':\n",
        "                section_for_synapse = basals[branch_index]\n",
        "              elif all_trunk_sec_type[section_to_expand_index]=='apic':\n",
        "                section_for_synapse = apicals[branch_index]\n",
        "              else:\n",
        "                raise(all_trunk_sec_type[section_to_expand_index],' is not \"apic\" or \"dend\"')\n",
        "              \n",
        "              #adjust x location to the point on the branch that has the same electrotonic length as originally\n",
        "\n",
        "              dend_elec_L=trunk_properties[section_to_expand_index].electrotonic_length+branch_properties[section_to_expand_index]\n",
        "              on_basal_subtree = not (has_apical and section_to_expand_index == 0)\n",
        "              x = find_branch_synapse_X(original_cell,\n",
        "                   synapse_location,\n",
        "                   on_basal_subtree,\n",
        "                   imp_obj,\n",
        "                   subtree_input_impedance,\n",
        "                   dend_elec_L,\n",
        "                   subtree_ind_to_q[section_to_expand_index],\n",
        "                   trunk_properties=trunk_properties[section_to_expand_index], branch_properties=branch_properties[section_to_expand_index])\n",
        "              \n",
        "\n",
        "            # go over all point processes in this segment and see whether one\n",
        "            # of them has the same proporties of this synapse\n",
        "            # If there's such a synapse link the original NetCon with this point processes\n",
        "            # If not, move the synapse to this segment.\n",
        "            for PP in section_for_synapse(x).point_processes():\n",
        "                if type_of_point_process(PP) not in PP_params_dict:\n",
        "                    add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "                if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                    netcons_list[syn_index].setpost(PP)\n",
        "                    break\n",
        "            else:  # If for finish the loop -> first appearance of this synapse\n",
        "                synapse.loc(x, sec=section_for_synapse)\n",
        "                new_synapses_list.append(synapse)\n",
        "\n",
        "    # merging somatic and axonal synapses\n",
        "    synapses_per_seg = collections.defaultdict(list)\n",
        "    for synapse in soma_synapses_syn_to_netcon:\n",
        "        seg_pointer = synapse.get_segment()\n",
        "\n",
        "        for PP in synapses_per_seg[seg_pointer]:\n",
        "            if type_of_point_process(PP) not in PP_params_dict:\n",
        "                add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "            if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                soma_synapses_syn_to_netcon[synapse].setpost(PP)\n",
        "                break\n",
        "        else:  # If for finish the loop -> first appearance of this synapse\n",
        "            synapse.loc(seg_pointer.x, sec=seg_pointer.sec)\n",
        "            new_synapses_list.append(synapse)\n",
        "            synapses_per_seg[seg_pointer].append(synapse)\n",
        "\n",
        "    return new_synapses_list, subtree_ind_to_q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONQKr9xtlkeh"
      },
      "outputs": [],
      "source": [
        "def create_seg_to_seg(original_cell,\n",
        "                      section_per_subtree_index,\n",
        "                      sections_to_expand,\n",
        "                      mapping_sections_to_subtree_index,\n",
        "                      all_trunk_properties, all_branch_properties,\n",
        "                      has_apical,\n",
        "                      apicals,\n",
        "                      basals,\n",
        "                      subtree_ind_to_q,\n",
        "                      mapping_type,\n",
        "                      reduction_frequency,\n",
        "                      trunks, branches):\n",
        "    '''create mapping between segments in the original model to segments in the reduced model\n",
        "       if mapping_type == impedance the mapping will be a response to the\n",
        "       transfer impedance of each segment to the soma (like the synapses)\n",
        "       if mapping_type == distance  the mapping will be a response to the\n",
        "       distance of each segment to the soma (like the synapses) NOT IMPLEMENTED\n",
        "       YET\n",
        "       '''\n",
        "\n",
        "    assert mapping_type == 'impedance', 'distance mapping not implemented yet'\n",
        "    # the keys are the segments of the original model, the values are the\n",
        "    # segments of the reduced model\n",
        "    original_seg_to_reduced_seg = {}\n",
        "    reduced_seg_to_original_seg = collections.defaultdict(list)\n",
        "    for subtree_index in section_per_subtree_index: #iterate through original sections\n",
        "        for sec in section_per_subtree_index[subtree_index]:\n",
        "            for seg in sec:\n",
        "                synapse_location = find_synapse_loc(seg, mapping_sections_to_subtree_index)\n",
        "                imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "                    sections_to_expand[subtree_index], reduction_frequency)\n",
        "\n",
        "                # if synapse is on the apical subtree\n",
        "                on_basal_subtree = not (has_apical and subtree_index == 0)\n",
        "\n",
        "                mid_of_segment_loc, on_trunk = expand_synapse(\n",
        "                    original_cell,\n",
        "                    synapse_location,\n",
        "                    on_basal_subtree,\n",
        "                    imp_obj,\n",
        "                    subtree_input_impedance,\n",
        "                    all_trunk_properties[subtree_index], all_branch_properties[subtree_index],\n",
        "                    subtree_ind_to_q[subtree_index])\n",
        "                if on_trunk:\n",
        "                  new_section_for_synapse = trunks[subtree_index]\n",
        "                else:\n",
        "                  new_sections_for_synapse = branches[subtree_index] \n",
        "\n",
        "\n",
        "                reduced_seg = new_section_for_synapse(mid_of_segment_loc)\n",
        "                original_seg_to_reduced_seg[seg] = reduced_seg\n",
        "                reduced_seg_to_original_seg[reduced_seg].append(seg)\n",
        "\n",
        "    return original_seg_to_reduced_seg, dict(reduced_seg_to_original_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeLsykmWtP-Z"
      },
      "outputs": [],
      "source": [
        "def copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type='impedance'):\n",
        "    ''' copies the mechanisms from the original model to the reduced model'''\n",
        "\n",
        "    # copy mechanisms\n",
        "    # this is needed for the case where some segements were not been mapped\n",
        "    mech_names_per_segment = collections.defaultdict(list)\n",
        "    vals_per_mech_per_segment = {}\n",
        "    for reduced_seg, original_segs in reduced_seg_to_original_seg.items():\n",
        "        vals_per_mech_per_segment[reduced_seg] = collections.defaultdict(list)\n",
        "\n",
        "        for original_seg in original_segs:\n",
        "            for mech_name, mech_params in segment_to_mech_vals[original_seg].items():\n",
        "                for param_name, param_value in mech_params.items():\n",
        "                    vals_per_mech_per_segment[reduced_seg][param_name].append(param_value)\n",
        "\n",
        "                mech_names_per_segment[reduced_seg].append(mech_name)\n",
        "                reduced_seg.sec.insert(mech_name)\n",
        "\n",
        "        for param_name, param_values in vals_per_mech_per_segment[reduced_seg].items():\n",
        "            setattr(reduced_seg, param_name, np.mean(param_values))\n",
        "\n",
        "    all_segments = []\n",
        "    if apic is not None:\n",
        "        all_segments.extend(list(apic))\n",
        "\n",
        "    for bas in basals:\n",
        "        all_segments.extend(list(bas))\n",
        "\n",
        "    if len(all_segments) != len(reduced_seg_to_original_seg):\n",
        "        logger.warning('There is no segment to segment copy, it means that some segments in the'\n",
        "                    'reduced model did not receive channels from the original cell.'\n",
        "                    'Trying to compensate by copying channels from neighboring segments')\n",
        "        handle_orphan_segments(original_seg_to_reduced_seg,\n",
        "                               all_segments,\n",
        "                               vals_per_mech_per_segment,\n",
        "                               mech_names_per_segment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh5WAIAUWmVO"
      },
      "outputs": [],
      "source": [
        "def cable_expander(original_cell,\n",
        "                     sections_to_expand_list, \n",
        "                     furcations_x, \n",
        "                     nbranches,\n",
        "                     synapses_list,\n",
        "                     netcons_list,\n",
        "                     reduction_frequency,\n",
        "                     model_filename='model.hoc',\n",
        "                     total_segments_manual=-1,\n",
        "                     PP_params_dict=None,\n",
        "                     mapping_type='impedance',\n",
        "                     return_seg_to_seg=False,\n",
        "                     ):\n",
        "\n",
        "    '''\n",
        "    Receives an instance of a cell with a loaded full morphology, a list of\n",
        "    synapse objects, a list of NetCon objects (the i'th netcon in the list\n",
        "    should correspond to the i'th synapse), the filename (string) of the model\n",
        "    template hoc file that the cell was instantiated from, the desired\n",
        "    reduction frequency as a float, optional parameter for the approximate\n",
        "    desired number of segments in the new model (if this parameter is empty,\n",
        "    the number of segments will be such that there is a segment for every 0.1\n",
        "    lambda), and an optional param for the point process to be compared before\n",
        "    deciding on whether to merge a synapse or not and reduces the cell (using\n",
        "    the given reduction_frequency). Creates a reduced instance using the model\n",
        "    template in the file whose filename is given as a parameter, and merges\n",
        "    synapses of the same type that get mapped to the same segment\n",
        "    (same \"reduced\" synapse object for them all, but different NetCon objects).\n",
        "    model_filename : model.hoc  will use a default template\n",
        "    total_segments_manual: sets the number of segments in the reduced model\n",
        "                           can be either -1, a float between 0 to 1, or an int\n",
        "                           if total_segments_manual = -1 will do automatic segmentation\n",
        "                           if total_segments_manual>1 will set the number of segments\n",
        "                           in the reduced model to total_segments_manual\n",
        "                           if 0>total_segments_manual>1 will automatically segment the model\n",
        "                           but if the automatic segmentation will produce a segment number that\n",
        "                           is lower than original_number_of_segments*total_segments_manual it\n",
        "                           will set the number of segments in the reduced model to:\n",
        "                           original_number_of_segments*total_segments_manual\n",
        "    return_seg_to_seg: if True the function will also return a textify version of the mapping\n",
        "                       between the original segments to the reduced segments \n",
        "    Returns the new reduced cell, a list of the new synapses, and the list of\n",
        "    the inputted netcons which now have connections with the new synapses.\n",
        "    Notes:\n",
        "    1) The original cell instance, synapses and Netcons given as arguments are altered\n",
        "    by the function and cannot be used outside of it in their original context.\n",
        "    2) Synapses are determined to be of the same type and mergeable if their reverse\n",
        "    potential, tau1 and tau2 values are identical.\n",
        "    3) Merged synapses are assigned a single new synapse object that represents them\n",
        "    all, but keep their original NetCon objects. Each such NetCon now connects the\n",
        "    original synapse's NetStim with\n",
        "    the reduced synapse.\n",
        "    '''\n",
        "    for nbranch in nbranches:\n",
        "      if type(nbranch) is not int:\n",
        "        raise TypeError('nbranches must be array of int')\n",
        "\n",
        "    if PP_params_dict is None:\n",
        "        PP_params_dict = {}\n",
        "    print('init')\n",
        "    h.init()\n",
        "    \n",
        "    model_obj_name = load_model(model_filename)\n",
        "    \n",
        "    print('model loaded')\n",
        "    # finds soma properties\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "    print('soma found')\n",
        "    print(soma.cm)\n",
        "    \n",
        "\n",
        "    soma_cable = CableParams(length=soma.L, diam=soma.diam, space_const=None,\n",
        "                             cm=soma.cm, rm=1.0 / soma.g_pas, ra=soma.Ra, e_pas=soma.e_pas,\n",
        "                             electrotonic_length=None,type='soma',furcation_x=None)\n",
        "\n",
        "    has_apical = len(list(original_cell.hoc_model.apical)) != 0\n",
        "\n",
        "    soma_ref = h.SectionRef(sec=soma)\n",
        "    sections_to_keep, is_section_to_keep_soma_parent, soma_sections_to_keep_x = find_and_disconnect_sections_to_keep(soma_ref,sections_to_expand)\n",
        "#     roots_of_subtrees, num_of_subtrees = gather_subtrees(soma_ref)\n",
        "# # ************************************stopping point today*********************************\n",
        "    print('disconnected kept sections')\n",
        "    sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index = \\\n",
        "        gather_cell_subtrees(sections_to_expand)\n",
        "\n",
        "\n",
        "    # preparing for expansion\n",
        "\n",
        "    # remove active conductances and get seg_to_mech dictionary\n",
        "    segment_to_mech_vals=create_segments_to_mech_vals(sections_to_expand) ######################################***************** Check\n",
        "\n",
        "    # disconnects all the sections_to_expand from the soma\n",
        "    subtrees_xs = []\n",
        "    for section_to_expand in sections_to_expand:\n",
        "        subtrees_xs.append(section_to_expand.parentseg().x)\n",
        "        h.disconnect(sec=section_to_expand)\n",
        "\n",
        "    # expanding the subtrees\n",
        "    all_trunk_properties=[] #list of all trunk cable properties\n",
        "    all_branch_properties=[] #list of all branch cable properties\n",
        "    all_trunk_types=[]\n",
        "    for i,sec in enumerate(sections_to_expand):\n",
        "      trunk_properties,branch_properties,trunk_type=expand_cable(sections_to_expand[i], reduction_frequency, furcations_x[i], nbranches[i])\n",
        "      all_trunk_properties.append(trunk_properties)\n",
        "      all_branch_properties.append(branch_properties)\n",
        "      all_trunk_types.append(trunk_type)\n",
        "    trunk_nsegs = calculate_nsegs_from_lambda(all_trunk_properties)\n",
        "    branch_nsegs = calculate_nsegs_from_lambda(all_branch_properties)\n",
        "\n",
        "    # trunk_properties,branch_properties = [expand_cable(sections_to_expand[i], reduction_frequency, furcations_x, nbranches)\n",
        "    #                         for i in sections_to_expand]\n",
        "\n",
        "    # if total_segments_manual > 1:\n",
        "    #     new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "    #                                                        total_segments_manual)\n",
        "    # else:\n",
        "    #     new_cables_nsegs = calculate_nsegs_from_lambda(new_cable_properties)\n",
        "    #     if total_segments_manual > 0:\n",
        "    #         original_cell_seg_n = (sum(i.nseg for i in list(original_cell.basal)) +\n",
        "    #                                sum(i.nseg for i in list(original_cell.apical))\n",
        "    #                                )\n",
        "    #         min_reduced_seg_n = int(round((total_segments_manual * original_cell_seg_n)))\n",
        "    #         if sum(new_cables_nsegs) < min_reduced_seg_n:\n",
        "    #             logger.debug(\"number of segments calculated using lambda is {}, \"\n",
        "    #                   \"the original cell had {} segments.  \"\n",
        "    #                   \"The min reduced segments is set to {}% of reduced cell segments\".format(\n",
        "    #                       sum(new_cables_nsegs),\n",
        "    #                       original_cell_seg_n,\n",
        "    #                       total_segments_manual * 100))\n",
        "    #             logger.debug(\"the reduced cell nseg is set to %s\" % min_reduced_seg_n)\n",
        "    #             new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "    #                                                                min_reduced_seg_n)\n",
        "                \n",
        "\n",
        "    cell, basals, apicals, trunk_sec_type_list_indices, trunks, branches = create_dendritic_cell(soma_cable,\n",
        "                                                                                has_apical,\n",
        "                                                                                original_cell,\n",
        "                                                                                model_obj_name,\n",
        "                                                                                all_trunk_properties, all_branch_properties, nbranches,\n",
        "                                                                                sections_to_expand,sections_to_keep, #new_cable_properties,  #lists for each expansion\n",
        "                                                                                trunk_nsegs, branch_nsegs, #new_cables_nsegs,\n",
        "                                                                                subtrees_xs)\n",
        "\n",
        "\n",
        "    new_synapses_list, subtree_ind_to_q = adjust_new_tree_synapses(\n",
        "        len(sections_to_expand),\n",
        "        all_trunk_properties, all_branch_properties, nbranches, furcations_x, all_trunk_types, trunk_sec_type_list_indices,\n",
        "        PP_params_dict,\n",
        "        synapses_list,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        netcons_list,\n",
        "        has_apical,\n",
        "        sections_to_expand,\n",
        "        original_cell,\n",
        "        basals, apicals,\n",
        "        cell,\n",
        "        reduction_frequency)\n",
        "\n",
        "\n",
        "    # create segment to segment mapping\n",
        "    original_seg_to_reduced_seg, reduced_seg_to_original_seg, = create_seg_to_seg(\n",
        "        original_cell,\n",
        "        section_per_subtree_index,\n",
        "        sections_to_expand,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        all_trunk_properties, all_branch_properties,\n",
        "        has_apical,\n",
        "        apicals,\n",
        "        basals,\n",
        "        subtree_ind_to_q,\n",
        "        mapping_type,\n",
        "        reduction_frequency,\n",
        "        trunks, branches)\n",
        "\n",
        "    # copy active mechanisms\n",
        "    copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        cell.apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type)\n",
        "    \n",
        "    if return_seg_to_seg:\n",
        "        original_seg_to_reduced_seg_text = textify_seg_to_seg(original_seg_to_reduced_seg)\n",
        "\n",
        "    # Connect disconnected sections back to the soma\n",
        "    if len(sections_to_keep) > 0:\n",
        "      for i,sec in enumerate(sections_to_keep):\n",
        "        if is_section_to_keep_soma_parent[i]:\n",
        "            soma.connect(sec)\n",
        "        else:\n",
        "            sections_to_keep[i].connect(soma, soma_sections_to_keep_x)\n",
        "\n",
        "    # Now we delete the original model\n",
        "    for section in sections_to_expand:\n",
        "        with push_section(section):\n",
        "            h.delete_section()\n",
        "    \n",
        "    #now we add the sections to our list\n",
        "    if cell.hoc_model.axon is not None:\n",
        "      cell.axon = cell.hoc_model.axon # cell.axon = axon_section\n",
        "    if cell.hoc_model.dend is not None:\n",
        "      cell.dend = cell.hoc_model.dend\n",
        "    if cell.hoc_model.apic is not None:\n",
        "      cell.apic = cell.hoc_model.apic\n",
        "\n",
        "    # # now we add the kept sections to our list\n",
        "    # for i,sec in enumerate(sections_to_keep:\n",
        "    #   sec_type=sec.name().split(\".\")[1][:4]\n",
        "    #   cell.getattr(sec_type)[].append(sec) #might not work\n",
        "\n",
        "    with push_section(cell.hoc_model.soma[0]):\n",
        "        h.delete_section()\n",
        "    if return_seg_to_seg:\n",
        "        return cell, new_synapses_list, netcons_list, original_seg_to_reduced_seg_text\n",
        "    else:\n",
        "        return cell, new_synapses_list, netcons_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDme8Bwj4lzX",
        "outputId": "b17865fd-0277-48d7-a2f2-2747281e9c69"
      },
      "outputs": [],
      "source": [
        "################### user specs: ###############\n",
        "sections_to_expand=[reduced_cell.hoc_model.apic[0]] # list of sections to expand\n",
        "furcations_x=[0.289004] # list of x loc branching points corresponding to above list\n",
        "nbranches=[4] #list of desired number of branches for each furcation point\n",
        "################################################\n",
        "\n",
        "# reduced_dendritic_cell, synapses_list, netcons_list, txt = cable_expander(reduced_cell.hoc_model, sections_to_expand, furcations_x, nbranches, \n",
        "#                                                                           synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)\n",
        "#kernal was crashing because deleted section\n",
        "reduced_dendritic_cell, synapses_list, netcons_list, txt = cable_expander(reduced_cell, sections_to_expand, furcations_x, nbranches, \n",
        "                                                                          synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WKYx7-0VB_V"
      },
      "outputs": [],
      "source": [
        "# extract mechanisms from deleted segments\n",
        "for seg in reduced_cell.hoc_model.apic[0]:\n",
        "  # print(seg)\n",
        "  for mech in seg:\n",
        "    print(mech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H_UVB1bCz2c"
      },
      "outputs": [],
      "source": [
        "#this segment is then centered this far from the soma\n",
        "reduced_nexus_dist=0.289004*2424.182421257107 # length of apical cylinder * x loc from above\n",
        "print(reduced_nexus_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMhTiEznToRY"
      },
      "outputs": [],
      "source": [
        "# shorten apical cylinder to nexus branching point.\n",
        "# print(reduced_cell.hoc_model.apic[0].L)\n",
        "# reduced_cell.hoc_model.apic[0].L=reduced_nexus_dist\n",
        "# print(reduced_cell.hoc_model.apic[0].L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2fw1t5eUXG2"
      },
      "outputs": [],
      "source": [
        "dir(reduced_cell.hoc_model.apic[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpP2b24LBVHJ"
      },
      "outputs": [],
      "source": [
        "# dir(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mcPrkIjBlWt"
      },
      "outputs": [],
      "source": [
        "# for key, value in txt.items():\n",
        "#     print(\"{:<10}\".format(value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGwLfdxo5Puw"
      },
      "source": [
        "#Show Complex and Reduced Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVqP8OGNewZV"
      },
      "source": [
        "# Citation\n",
        "O. Amsalem, G. Eyal, N. Rogozinski, M. Gevaert, P. Kumbhar, F. Schrmann, I. Segev. An efficient analytical reduction of detailed nonlinear neuron models. Nat. Commun., 11 (2020), p. 288"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM2NLKEpfSMFncXWdqX7KYj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
